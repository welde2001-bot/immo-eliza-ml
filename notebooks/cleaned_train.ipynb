{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3696ff",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e7fa8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15232 entries, 0 to 15231\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   build_year          6226 non-null   object \n",
      " 1   facades             10088 non-null  float64\n",
      " 2   garden              15232 non-null  object \n",
      " 3   living_area         13504 non-null  object \n",
      " 4   locality_name       15012 non-null  object \n",
      " 5   number_rooms        13980 non-null  object \n",
      " 6   postal_code         15008 non-null  float64\n",
      " 7   price               14389 non-null  float64\n",
      " 8   property_id         15232 non-null  object \n",
      " 9   property_type       14236 non-null  object \n",
      " 10  property_url        15232 non-null  object \n",
      " 11  state               11116 non-null  object \n",
      " 12  swimming_pool       15232 non-null  object \n",
      " 13  terrace             13832 non-null  object \n",
      " 14  province            15008 non-null  object \n",
      " 15  property_type_name  14232 non-null  object \n",
      " 16  state_mapped        11112 non-null  object \n",
      "dtypes: float64(3), object(14)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5f41e6b2-b4ee-4bc8-ab65-81813d9ada78",
       "rows": [
        [
         "build_year",
         "9006"
        ],
        [
         "facades",
         "5144"
        ],
        [
         "garden",
         "0"
        ],
        [
         "living_area",
         "1728"
        ],
        [
         "locality_name",
         "220"
        ],
        [
         "number_rooms",
         "1252"
        ],
        [
         "postal_code",
         "224"
        ],
        [
         "price",
         "843"
        ],
        [
         "property_id",
         "0"
        ],
        [
         "property_type",
         "996"
        ],
        [
         "property_url",
         "0"
        ],
        [
         "state",
         "4116"
        ],
        [
         "swimming_pool",
         "0"
        ],
        [
         "terrace",
         "1400"
        ],
        [
         "province",
         "224"
        ],
        [
         "property_type_name",
         "1000"
        ],
        [
         "state_mapped",
         "4120"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 17
       }
      },
      "text/plain": [
       "build_year            9006\n",
       "facades               5144\n",
       "garden                   0\n",
       "living_area           1728\n",
       "locality_name          220\n",
       "number_rooms          1252\n",
       "postal_code            224\n",
       "price                  843\n",
       "property_id              0\n",
       "property_type          996\n",
       "property_url             0\n",
       "state                 4116\n",
       "swimming_pool            0\n",
       "terrace               1400\n",
       "province               224\n",
       "property_type_name    1000\n",
       "state_mapped          4120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\welde\\Desktop\\immo-eliza-ml\")  # Change Python's working directory so that all relative paths are resolved from your project root\n",
    "\n",
    "\n",
    "# load the data set\n",
    "\n",
    "df = pd.read_csv(\"data/raw/raw.csv\")\n",
    "df.head()      # \n",
    "df.shape       # Check dataset shape\n",
    "df.info()       # Inspect column data types\n",
    "df.describe()    #Summary statistics\n",
    "df.isna().sum()   #missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f7473",
   "metadata": {},
   "source": [
    "## DATA CLEANING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f226214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def enhanced_clean(\n",
    "        path=\"data/raw/raw.csv\",\n",
    "        save_path=\"data/processed/cleaned_v2.csv\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    FINAL unified cleaning pipeline for ImmoEliza.\n",
    "    - Merges basic cleaning + enhanced cleaning\n",
    "    - Handles numeric sanity\n",
    "    - Normalizes booleans\n",
    "    - Converts numeric-like columns\n",
    "    - Removes locality_name completely\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Load raw-cleaned data\n",
    "    df = pd.read_csv(path, dtype={\"postal_code\": \"string\"}).copy()\n",
    "\n",
    "    # 2. Drop useless columns\n",
    "    drop_cols = [\n",
    "        \"property_id\",\n",
    "        \"property_url\",\n",
    "        \"property_type_name\",\n",
    "        \"state_mapped\",\n",
    "        \"locality_name\"      \n",
    "    ]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    # 3. Normalize boolean-like columns\n",
    "    bool_cols = [\"garden\", \"terrace\", \"swimming_pool\"]\n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = (\n",
    "                df[col].astype(str).str.lower().str.strip()\n",
    "                .replace({\n",
    "                    \"1\": \"yes\", \"true\": \"yes\", \"yes\": \"yes\",\n",
    "                    \"0\": \"no\", \"false\": \"no\", \"no\": \"no\"\n",
    "                })\n",
    "            )\n",
    "\n",
    "    # 4. Convert numeric-like columns (comma → dot)\n",
    "    numeric_cols = [\"build_year\", \"number_rooms\", \"facades\", \"living_area\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.replace(\",\", \".\", regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Ensure price numeric\n",
    "    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "    # Postal code remains categorical\n",
    "    df[\"postal_code\"] = df[\"postal_code\"].astype(\"string\")\n",
    "\n",
    "    # 5. Numeric sanity constraints\n",
    "    df.loc[df[\"build_year\"] < 1800, \"build_year\"] = np.nan\n",
    "    df.loc[df[\"build_year\"] > 2025, \"build_year\"] = np.nan\n",
    "\n",
    "    df.loc[df[\"number_rooms\"] <= 0, \"number_rooms\"] = np.nan\n",
    "    df.loc[df[\"number_rooms\"] > 12, \"number_rooms\"] = np.nan\n",
    "\n",
    "    df.loc[df[\"living_area\"] < 10, \"living_area\"] = np.nan\n",
    "    df.loc[df[\"living_area\"] > 500, \"living_area\"] = np.nan\n",
    "\n",
    "    df = df[df[\"price\"] >= 10000]\n",
    "    df.loc[df[\"price\"] > 7_500_000, \"price\"] = np.nan\n",
    "    df = df[df[\"price\"].notna()]\n",
    "\n",
    "    df[\"province\"] = df[\"province\"].astype(str).str.strip().replace(\"nan\", np.nan)\n",
    "\n",
    "    # 6. LOCALITY REMOVED — nothing here\n",
    "\n",
    "    # 7. Save\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"Enhanced Cleaned dataset saved to: {save_path}\")\n",
    "    print(\"Final shape:\", df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a29adfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Cleaned dataset saved to: data/processed/cleaned_v2.csv\n",
      "Final shape: (14374, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "build_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "facades",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "garden",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "living_area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "number_rooms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postal_code",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "property_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "swimming_pool",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "terrace",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "province",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9903d962-7047-4019-b26a-d75dcea281fd",
       "rows": [
        [
         "0",
         "1996.0",
         "2.0",
         "yes",
         "270.0",
         "4.0",
         "1853.0",
         "580000.0",
         "Residence",
         "Excellent",
         "no",
         "yes",
         "Flemish Brabant"
        ],
        [
         "1",
         "1991.0",
         "4.0",
         "yes",
         "218.0",
         "5.0",
         "1341.0",
         "695000.0",
         "Residence",
         "Excellent",
         "yes",
         "yes",
         "Walloon Brabant"
        ],
        [
         "2",
         "1970.0",
         "4.0",
         "no",
         "135.0",
         "3.0",
         "1300.0",
         "249000.0",
         "Apartment",
         "To be renovated",
         "no",
         "yes",
         "Walloon Brabant"
        ],
        [
         "3",
         "1959.0",
         "3.0",
         "yes",
         "176.0",
         "3.0",
         "1853.0",
         "499000.0",
         "Residence",
         "Normal",
         "no",
         "yes",
         "Flemish Brabant"
        ],
        [
         "4",
         "2007.0",
         "4.0",
         "yes",
         "200.0",
         "4.0",
         "1341.0",
         "650000.0",
         "Residence",
         "Excellent",
         "no",
         "yes",
         "Walloon Brabant"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build_year</th>\n",
       "      <th>facades</th>\n",
       "      <th>garden</th>\n",
       "      <th>living_area</th>\n",
       "      <th>number_rooms</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>state</th>\n",
       "      <th>swimming_pool</th>\n",
       "      <th>terrace</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Flemish Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>218.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>695000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>To be renovated</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>176.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>499000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Flemish Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   build_year  facades garden  living_area  number_rooms postal_code  \\\n",
       "0      1996.0      2.0    yes        270.0           4.0      1853.0   \n",
       "1      1991.0      4.0    yes        218.0           5.0      1341.0   \n",
       "2      1970.0      4.0     no        135.0           3.0      1300.0   \n",
       "3      1959.0      3.0    yes        176.0           3.0      1853.0   \n",
       "4      2007.0      4.0    yes        200.0           4.0      1341.0   \n",
       "\n",
       "      price property_type            state swimming_pool terrace  \\\n",
       "0  580000.0     Residence        Excellent            no     yes   \n",
       "1  695000.0     Residence        Excellent           yes     yes   \n",
       "2  249000.0     Apartment  To be renovated            no     yes   \n",
       "3  499000.0     Residence           Normal            no     yes   \n",
       "4  650000.0     Residence        Excellent            no     yes   \n",
       "\n",
       "          province  \n",
       "0  Flemish Brabant  \n",
       "1  Walloon Brabant  \n",
       "2  Walloon Brabant  \n",
       "3  Flemish Brabant  \n",
       "4  Walloon Brabant  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "cleaned_df = enhanced_clean(\n",
    "    path=\"data/raw/raw.csv\",\n",
    "    save_path=\"data/processed/cleaned_v2.csv\"\n",
    ")\n",
    "\n",
    "cleaned_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27445a2f",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32db2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def feature_engineering(\n",
    "        path=\"data/processed/cleaned_v2.csv\",\n",
    "        save_path=\"data/processed/feature_engineered.csv\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Feature Engineering for ImmoEliza.\n",
    "\n",
    "    Adds:\n",
    "    - build_year features (age, decade, age flags)\n",
    "    - region mapping from province (province is uppercase NL)\n",
    "    - boolean flags (garden/terrace/swimming_pool)\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path, dtype={\"postal_code\": \"string\"}).copy()\n",
    "\n",
    "    # Postal code: clean 4-digit string or \"unknown\"\n",
    "    df[\"postal_code\"] = (\n",
    "        df[\"postal_code\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.extract(r\"(\\d{4})\", expand=False)\n",
    "        .fillna(\"unknown\")\n",
    "        .astype(\"string\")\n",
    "    )\n",
    "\n",
    "    # Build-year features\n",
    "    if \"build_year\" in df.columns:\n",
    "        build_year_num = pd.to_numeric(df[\"build_year\"], errors=\"coerce\")\n",
    "        current_year = datetime.now().year\n",
    "\n",
    "        df[\"house_age\"] = current_year - build_year_num\n",
    "        df.loc[df[\"house_age\"] < 0, \"house_age\"] = np.nan\n",
    "\n",
    "        df[\"is_new_build\"] = (df[\"house_age\"] <= 5).astype(\"Int64\")\n",
    "        df[\"is_recent\"]    = (df[\"house_age\"] <= 20).astype(\"Int64\")\n",
    "        df[\"is_old\"]       = (df[\"house_age\"] >= 50).astype(\"Int64\")\n",
    "\n",
    "        df[\"build_decade\"] = (build_year_num // 10 * 10).astype(\"Int64\")\n",
    "    else:\n",
    "        df[\"house_age\"] = np.nan\n",
    "        df[\"is_new_build\"] = np.nan\n",
    "        df[\"is_recent\"] = np.nan\n",
    "        df[\"is_old\"] = np.nan\n",
    "        df[\"build_decade\"] = np.nan\n",
    "\n",
    "    # Region from province (province is uppercase NL in your pipeline)\n",
    "    region_map_nl_upper = {\n",
    "        \"ANTWERPEN\": \"Flanders\",\n",
    "        \"OOST-VLAANDEREN\": \"Flanders\",\n",
    "        \"WEST-VLAANDEREN\": \"Flanders\",\n",
    "        \"LIMBURG\": \"Flanders\",\n",
    "        \"VLAAMS-BRABANT\": \"Flanders\",\n",
    "        \"WAALS-BRABANT\": \"Wallonia\",\n",
    "        \"HENEGOUWEN\": \"Wallonia\",\n",
    "        \"LUIK\": \"Wallonia\",\n",
    "        \"LUXEMBURG\": \"Wallonia\",\n",
    "        \"NAMEN\": \"Wallonia\",\n",
    "        \"BRUSSEL\": \"Brussels\",\n",
    "    }\n",
    "\n",
    "    if \"province\" in df.columns:\n",
    "        df[\"region\"] = (\n",
    "            df[\"province\"]\n",
    "            .astype(\"string\")\n",
    "            .str.strip()\n",
    "            .str.upper()\n",
    "            .map(region_map_nl_upper)\n",
    "            .fillna(\"unknown\")\n",
    "            .astype(\"string\")\n",
    "        )\n",
    "    else:\n",
    "        df[\"region\"] = \"unknown\"\n",
    "\n",
    "    # Boolean flags\n",
    "    bool_map = {\"yes\": 1, \"no\": 0}\n",
    "    for col in [\"garden\", \"terrace\", \"swimming_pool\"]:\n",
    "        if col in df.columns:\n",
    "            df[col + \"_flag\"] = (\n",
    "                df[col]\n",
    "                .astype(\"string\")\n",
    "                .str.strip()\n",
    "                .str.lower()\n",
    "                .map(bool_map)\n",
    "                .astype(\"Int64\")\n",
    "            )\n",
    "        else:\n",
    "            df[col + \"_flag\"] = np.nan\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"Feature-engineered dataset saved to: {save_path}\")\n",
    "    print(\"Final shape:\", df.shape)\n",
    "    print(\"Region counts:\\n\", df[\"region\"].value_counts(dropna=False))\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6829503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered dataset saved to: data/processed/feature_engineered.csv\n",
      "Final shape: (14374, 21)\n",
      "Region counts:\n",
      " region\n",
      "Flanders    7040\n",
      "Wallonia    5925\n",
      "Brussels    1409\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Columns: ['build_year', 'facades', 'garden', 'living_area', 'number_rooms', 'postal_code', 'price', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'region', 'garden_flag', 'terrace_flag', 'swimming_pool_flag']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "postal_code",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "region",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "2e441d9f-3ced-4e13-8cc9-f5eea47e6183",
       "rows": [
        [
         "0",
         "1853",
         "VLAAMS-BRABANT",
         "Flanders"
        ],
        [
         "1",
         "1341",
         "WAALS-BRABANT",
         "Wallonia"
        ],
        [
         "2",
         "1300",
         "WAALS-BRABANT",
         "Wallonia"
        ],
        [
         "3",
         "1853",
         "VLAAMS-BRABANT",
         "Flanders"
        ],
        [
         "4",
         "1341",
         "WAALS-BRABANT",
         "Wallonia"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1853</td>\n",
       "      <td>VLAAMS-BRABANT</td>\n",
       "      <td>Flanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1341</td>\n",
       "      <td>WAALS-BRABANT</td>\n",
       "      <td>Wallonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300</td>\n",
       "      <td>WAALS-BRABANT</td>\n",
       "      <td>Wallonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>VLAAMS-BRABANT</td>\n",
       "      <td>Flanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1341</td>\n",
       "      <td>WAALS-BRABANT</td>\n",
       "      <td>Wallonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  postal_code        province    region\n",
       "0        1853  VLAAMS-BRABANT  Flanders\n",
       "1        1341   WAALS-BRABANT  Wallonia\n",
       "2        1300   WAALS-BRABANT  Wallonia\n",
       "3        1853  VLAAMS-BRABANT  Flanders\n",
       "4        1341   WAALS-BRABANT  Wallonia"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN IT\n",
    "\n",
    "df_fe = feature_engineering(\n",
    "    path=\"data/processed/cleaned_v2.csv\",\n",
    "    save_path=\"data/processed/feature_engineered.csv\"\n",
    ")\n",
    "\n",
    "df_fe[[\"postal_code\", \"province\", \"region\"]].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4f3b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "postal_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0fab9ded-04bd-4c6b-9242-d03c5e1b55be",
       "rows": [
        [
         "5000",
         "356"
        ],
        [
         "4000",
         "298"
        ],
        [
         "7000",
         "187"
        ],
        [
         "1180",
         "174"
        ],
        [
         "1140",
         "166"
        ],
        [
         "2500",
         "164"
        ],
        [
         "1000",
         "149"
        ],
        [
         "3970",
         "148"
        ],
        [
         "5100",
         "147"
        ],
        [
         "4020",
         "146"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "postal_code\n",
       "5000    356\n",
       "4000    298\n",
       "7000    187\n",
       "1180    174\n",
       "1140    166\n",
       "2500    164\n",
       "1000    149\n",
       "3970    148\n",
       "5100    147\n",
       "4020    146\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fe[\"postal_code\"].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90dedd",
   "metadata": {},
   "source": [
    "## PREPROCESS DATA (Pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbaed627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def split_data(df: pd.DataFrame, target: str = \"price\", test_size: float = 0.20, random_state: int = 42):\n",
    "    # Separate target (y) from features (X), then split into train/test\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def remove_outliers_from_train(X_train: pd.DataFrame, y_train: pd.Series):\n",
    "    # Remove outliers ONLY from training data (avoid leakage into test/validation)\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    cols_to_filter = [c for c in [\"price\", \"living_area\"] if c in df_train.columns]\n",
    "\n",
    "    def iqr_filter(df_: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "        # Standard IQR rule: keep values in [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "        q1 = df_[col].quantile(0.25)\n",
    "        q3 = df_[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        return df_[(df_[col] >= lower) & (df_[col] <= upper)]\n",
    "\n",
    "    for col in cols_to_filter:\n",
    "        df_train = iqr_filter(df_train, col)\n",
    "\n",
    "    # Optional hard cap on room counts (domain sanity rule)\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Training after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "def build_preprocessor(X_train: pd.DataFrame, drop_postal_code: bool = False) -> ColumnTransformer:\n",
    "    # Detect numeric and categorical columns by dtype\n",
    "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # Ensure postal_code is treated as categorical (unless we explicitly drop it)\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    # For linear models, dropping high-cardinality postal_code is often more stable\n",
    "    if drop_postal_code and \"postal_code\" in categorical_cols:\n",
    "        categorical_cols.remove(\"postal_code\")\n",
    "\n",
    "    # Numeric: impute missing values then scale\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    # Categorical: impute missing values then one-hot encode\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric + categorical transformations\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipeline, numeric_cols),\n",
    "            (\"cat\", categorical_pipeline, categorical_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "    print(\"\\nNumeric columns:\", numeric_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "    print(\"drop_postal_code:\", drop_postal_code)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def run_preprocessing_pipeline(\n",
    "    path: str = \"data/processed/feature_engineered.csv\",\n",
    "    target: str = \"price\",\n",
    "    drop_postal_code: bool = False,\n",
    "    remove_outliers: bool = False,\n",
    "    test_size: float = 0.20,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    # Load engineered dataset (postal_code kept as string so it can be categorical)\n",
    "    df = pd.read_csv(path, dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = split_data(\n",
    "        df, target=target, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Optional: outlier removal on TRAIN only\n",
    "    if remove_outliers:\n",
    "        X_train, y_train = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Build preprocessor using training data only (prevents leakage)\n",
    "    preprocessor = build_preprocessor(X_train, drop_postal_code=drop_postal_code)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ac2d141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 20)\n",
      "Test: (2875, 20)\n",
      "\n",
      "Numeric columns: ['build_year', 'facades', 'living_area', 'number_rooms', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'garden_flag', 'terrace_flag', 'swimming_pool_flag']\n",
      "Categorical columns: ['garden', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n",
      "drop_postal_code: False\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# RUN THE PIPELINE\n",
    "# ------------------------------------------------------------\n",
    "X_train_clean, X_test, y_train_clean, y_test, preprocessor = run_preprocessing_pipeline(\n",
    "    \"data/processed/feature_engineered.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff57939",
   "metadata": {},
   "source": [
    "## Tuned Linear Models: Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80df6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Evaluate a single split\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_split(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Train tuned linear models (Ridge, Lasso, ElasticNet)\n",
    "# -------------------------------------------------------------\n",
    "def train_tuned_linear_models(X_train, y_train, preprocessor):\n",
    "\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(),\n",
    "        \"Lasso\": Lasso(max_iter=10000),\n",
    "        \"ElasticNet\": ElasticNet(max_iter=10000)\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Ridge\": {\"model__alpha\": [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "        \"Lasso\": {\"model__alpha\": [0.001, 0.01, 0.1, 1, 10]},\n",
    "        \"ElasticNet\": {\n",
    "            \"model__alpha\": [0.001, 0.01, 0.1, 1],\n",
    "            \"model__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_distributions=param_grids[name],\n",
    "            n_iter=10,\n",
    "            scoring=\"neg_mean_absolute_error\",\n",
    "            cv=3,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Best params for {name}: {search.best_params_}\")\n",
    "        best_models[name] = search.best_estimator_\n",
    "\n",
    "    return best_models\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Full workflow: Train/Test only (NO validation)\n",
    "# -------------------------------------------------------------\n",
    "def run_tuned_linear_models(\n",
    "    X_train_clean, X_test,\n",
    "    y_train_clean, y_test,\n",
    "    preprocessor\n",
    "):\n",
    "\n",
    "    best_models = train_tuned_linear_models(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for name, model in best_models.items():\n",
    "        print(f\"\\n===== {name} Results =====\")\n",
    "\n",
    "        # Train performance\n",
    "        all_results.append(evaluate_split(\n",
    "            model, X_train_clean, y_train_clean, f\"{name} - Train\"\n",
    "        ))\n",
    "\n",
    "        # Test performance\n",
    "        all_results.append(evaluate_split(\n",
    "            model, X_test, y_test, f\"{name} - Test\"\n",
    "        ))\n",
    "\n",
    "        # Save model\n",
    "        model_path = f\"models/{name.lower()}_tuned.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"{name} model saved to {model_path}\")\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1deded6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Ridge: {'model__alpha': 10}\n",
      "\n",
      "Tuning Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Lasso: {'model__alpha': 10}\n",
      "\n",
      "Tuning ElasticNet...\n",
      "Best params for ElasticNet: {'model__l1_ratio': 0.1, 'model__alpha': 0.001}\n",
      "\n",
      "===== Ridge Results =====\n",
      "\n",
      "--- Ridge - Train Evaluation ---\n",
      "MAE:  92,755.73\n",
      "RMSE: 180,320.66\n",
      "R²:   0.5436\n",
      "\n",
      "--- Ridge - Test Evaluation ---\n",
      "MAE:  93,414.97\n",
      "RMSE: 170,091.12\n",
      "R²:   0.5461\n",
      "Ridge model saved to models/ridge_tuned.pkl\n",
      "\n",
      "===== Lasso Results =====\n",
      "\n",
      "--- Lasso - Train Evaluation ---\n",
      "MAE:  91,136.79\n",
      "RMSE: 176,515.45\n",
      "R²:   0.5627\n",
      "\n",
      "--- Lasso - Test Evaluation ---\n",
      "MAE:  93,969.48\n",
      "RMSE: 170,339.97\n",
      "R²:   0.5448\n",
      "Lasso model saved to models/lasso_tuned.pkl\n",
      "\n",
      "===== ElasticNet Results =====\n",
      "\n",
      "--- ElasticNet - Train Evaluation ---\n",
      "MAE:  92,818.28\n",
      "RMSE: 180,433.99\n",
      "R²:   0.5430\n",
      "\n",
      "--- ElasticNet - Test Evaluation ---\n",
      "MAE:  93,449.67\n",
      "RMSE: 170,144.60\n",
      "R²:   0.5458\n",
      "ElasticNet model saved to models/elasticnet_tuned.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3cda1480-d9a3-4edf-82e0-5ed27b49bfd8",
       "rows": [
        [
         "0",
         "Ridge - Train",
         "92755.72762997338",
         "180320.6614794741",
         "0.5436012074770784"
        ],
        [
         "1",
         "Ridge - Test",
         "93414.96559209071",
         "170091.12461106427",
         "0.5460875652398617"
        ],
        [
         "2",
         "Lasso - Train",
         "91136.78634464108",
         "176515.4525722017",
         "0.562660238149474"
        ],
        [
         "3",
         "Lasso - Test",
         "93969.47685567698",
         "170339.97294366168",
         "0.5447584190977557"
        ],
        [
         "4",
         "ElasticNet - Train",
         "92818.27512846378",
         "180433.99478445426",
         "0.5430273249500985"
        ],
        [
         "5",
         "ElasticNet - Test",
         "93449.66967263895",
         "170144.60076564603",
         "0.5458021028756039"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge - Train</td>\n",
       "      <td>92755.727630</td>\n",
       "      <td>180320.661479</td>\n",
       "      <td>0.543601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge - Test</td>\n",
       "      <td>93414.965592</td>\n",
       "      <td>170091.124611</td>\n",
       "      <td>0.546088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso - Train</td>\n",
       "      <td>91136.786345</td>\n",
       "      <td>176515.452572</td>\n",
       "      <td>0.562660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso - Test</td>\n",
       "      <td>93969.476856</td>\n",
       "      <td>170339.972944</td>\n",
       "      <td>0.544758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet - Train</td>\n",
       "      <td>92818.275128</td>\n",
       "      <td>180433.994784</td>\n",
       "      <td>0.543027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet - Test</td>\n",
       "      <td>93449.669673</td>\n",
       "      <td>170144.600766</td>\n",
       "      <td>0.545802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Split           MAE           RMSE        R2\n",
       "0       Ridge - Train  92755.727630  180320.661479  0.543601\n",
       "1        Ridge - Test  93414.965592  170091.124611  0.546088\n",
       "2       Lasso - Train  91136.786345  176515.452572  0.562660\n",
       "3        Lasso - Test  93969.476856  170339.972944  0.544758\n",
       "4  ElasticNet - Train  92818.275128  180433.994784  0.543027\n",
       "5   ElasticNet - Test  93449.669673  170144.600766  0.545802"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_linear_results = run_tuned_linear_models(\n",
    "    X_train_clean, X_test,\n",
    "    y_train_clean, y_test,\n",
    "    preprocessor\n",
    ")\n",
    "\n",
    "tuned_linear_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5daad",
   "metadata": {},
   "source": [
    "## Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24be7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Train Linear Regression (Pipeline = Preprocessor + LR)\n",
    "# ============================================================\n",
    "def train_linear_regression(X_train, y_train, preprocessor):\n",
    "    \"\"\"\n",
    "    Build and train a full pipeline:\n",
    "    - Preprocessor: ColumnTransformer\n",
    "    - Linear Regression model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nLinear Regression model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Evaluate one split (Train or Test)\n",
    "# ============================================================\n",
    "def evaluate_single_split(model, X, y, split_name=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given split.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5   # manual RMSE\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Evaluate Train + Test (NO validation)\n",
    "# ============================================================\n",
    "def evaluate_all_splits(model,\n",
    "                        X_train, y_train,\n",
    "                        X_test, y_test,\n",
    "                        model_name=\"Linear Regression\"):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Train\n",
    "    tr_mae, tr_rmse, tr_r2 = evaluate_single_split(\n",
    "        model, X_train, y_train, \"Train\"\n",
    "    )\n",
    "\n",
    "    # Test\n",
    "    te_mae, te_rmse, te_r2 = evaluate_single_split(\n",
    "        model, X_test, y_test, \"Test\"\n",
    "    )\n",
    "\n",
    "    # Summary DataFrame\n",
    "    df_results = pd.DataFrame([\n",
    "        {\"Model\": model_name, \"Split\": \"Train\", \"MAE\": tr_mae, \"RMSE\": tr_rmse, \"R2\": tr_r2},\n",
    "        {\"Model\": model_name, \"Split\": \"Test\", \"MAE\": te_mae, \"RMSE\": te_rmse, \"R2\": te_r2},\n",
    "    ])\n",
    "\n",
    "    print(\"\\n--- Summary Performance Table ---\")\n",
    "    print(df_results)\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Save model to disk\n",
    "# ============================================================\n",
    "def save_linear_regression(model, path=\"models/linear_regression.pkl\"):\n",
    "    \"\"\"\n",
    "    Save the full model pipeline (Preprocessor + Linear Regression).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    joblib.dump(model, path)\n",
    "\n",
    "    print(f\"\\nModel pipeline saved to: {path}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Full Linear Regression Workflow (Train/Test Only)\n",
    "# ============================================================\n",
    "def run_linear_regression(X_train_clean, X_test,\n",
    "                          y_train_clean, y_test,\n",
    "                          preprocessor):\n",
    "    \"\"\"\n",
    "    End-to-end workflow:\n",
    "    - Train LR model\n",
    "    - Evaluate on train/test (no validation)\n",
    "    - Save model\n",
    "    - Return model + performance table\n",
    "    \"\"\"\n",
    "\n",
    "    # Train model\n",
    "    model = train_linear_regression(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    scores = evaluate_all_splits(\n",
    "        model,\n",
    "        X_train_clean, y_train_clean,\n",
    "        X_test, y_test,\n",
    "        model_name=\"Linear Regression\"\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    save_linear_regression(model)\n",
    "\n",
    "    return model, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0129cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  90,395.48\n",
      "RMSE: 175,974.52\n",
      "R²:   0.5653\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  95,222.92\n",
      "RMSE: 171,256.19\n",
      "R²:   0.5398\n",
      "\n",
      "--- Summary Performance Table ---\n",
      "               Model  Split           MAE           RMSE        R2\n",
      "0  Linear Regression  Train  90395.478718  175974.520523  0.565337\n",
      "1  Linear Regression   Test  95222.922735  171256.188651  0.539848\n",
      "\n",
      "Model pipeline saved to: models/linear_regression.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c8662c91-d8aa-4119-8ff5-d35230b47ba6",
       "rows": [
        [
         "0",
         "Linear Regression",
         "Train",
         "90395.47871758373",
         "175974.520522921",
         "0.5653365886197743"
        ],
        [
         "1",
         "Linear Regression",
         "Test",
         "95222.92273463508",
         "171256.18865109503",
         "0.5398479894870365"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Train</td>\n",
       "      <td>90395.478718</td>\n",
       "      <td>175974.520523</td>\n",
       "      <td>0.565337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Test</td>\n",
       "      <td>95222.922735</td>\n",
       "      <td>171256.188651</td>\n",
       "      <td>0.539848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Split           MAE           RMSE        R2\n",
       "0  Linear Regression  Train  90395.478718  175974.520523  0.565337\n",
       "1  Linear Regression   Test  95222.922735  171256.188651  0.539848"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model, lr_results = run_linear_regression(\n",
    "    X_train_clean, X_test,\n",
    "    y_train_clean, y_test,\n",
    "    preprocessor\n",
    ")\n",
    "\n",
    "lr_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9b2d3",
   "metadata": {},
   "source": [
    "## leakage testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6292c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "def drift_check(X_train_clean, X_test, y_train_clean, y_test):\n",
    "    print(\"\\n==============================\")\n",
    "    print(\" DRIFT ANALYSIS STARTING\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Reconstruct full train/test DataFrames\n",
    "    # --------------------------------------------------------\n",
    "    train = X_train_clean.copy()\n",
    "    test = X_test.copy()\n",
    "\n",
    "    train[\"price\"] = y_train_clean.values\n",
    "    test[\"price\"] = y_test.values\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Identify columns\n",
    "    # --------------------------------------------------------\n",
    "    numeric_cols = train.select_dtypes(include=[\"float64\",\"int64\",\"Int64\"]).columns.tolist()\n",
    "    categorical_cols = train.select_dtypes(include=[\"object\",\"string\"]).columns.tolist()\n",
    "\n",
    "    # Ensure price treated as numeric\n",
    "    if \"price\" in categorical_cols:\n",
    "        categorical_cols.remove(\"price\")\n",
    "        numeric_cols.append(\"price\")\n",
    "\n",
    "    print(\"Numeric columns:\", numeric_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. Category Coverage Checks\n",
    "    # --------------------------------------------------------\n",
    "    def category_coverage(feature):\n",
    "        train_set = set(train[feature].dropna())\n",
    "        test_set = set(test[feature].dropna())\n",
    "\n",
    "        missing_in_train = test_set - train_set\n",
    "        missing_in_test = train_set - test_set\n",
    "\n",
    "        print(f\"\\n=== CATEGORY COVERAGE: {feature} ===\")\n",
    "        print(f\"Unique in train: {len(train_set)}\")\n",
    "        print(f\"Unique in test:  {len(test_set)}\")\n",
    "        print(f\"Present in TEST but NOT in train (unseen categories): {len(missing_in_train)}\")\n",
    "        if len(missing_in_train) > 0:\n",
    "            print(\"Examples:\", list(missing_in_train)[:15])\n",
    "        print(f\"Present in TRAIN but NOT in test: {len(missing_in_test)}\")\n",
    "\n",
    "    print(\"\\n========== CHECKING CATEGORY COVERAGE ==========\\n\")\n",
    "    for col in categorical_cols:\n",
    "        category_coverage(col)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. KS Tests for Numerical Drift\n",
    "    # --------------------------------------------------------\n",
    "    def ks_test(feature):\n",
    "        a = train[feature].dropna()\n",
    "        b = test[feature].dropna()\n",
    "\n",
    "        stat, p = ks_2samp(a, b)\n",
    "\n",
    "        print(f\"\\n=== KS TEST: {feature} ===\")\n",
    "        print(f\"KS statistic: {stat:.4f}\")\n",
    "        print(f\"P-value     : {p:.6f}\")\n",
    "\n",
    "        if p < 0.05:\n",
    "            print(\" -> SIGNIFICANT DRIFT DETECTED\")\n",
    "        else:\n",
    "            print(\" -> No significant drift\")\n",
    "\n",
    "    print(\"\\n========== KS-TEST FOR NUMERICAL FEATURES ==========\\n\")\n",
    "\n",
    "    # You normally do NOT test price for KS, but here we include it to see target drift\n",
    "    for col in numeric_cols:\n",
    "        ks_test(col)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. Target Drift Summary\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\n========== TARGET DRIFT (PRICE DISTRIBUTION) ==========\\n\")\n",
    "    print(\"Train price stats:\")\n",
    "    print(train[\"price\"].describe())\n",
    "\n",
    "    print(\"\\nTest price stats:\")\n",
    "    print(test[\"price\"].describe())\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6. Interaction Drift: Locality-level mean price\n",
    "    # --------------------------------------------------------\n",
    "    if \"locality_name\" in train.columns:\n",
    "        print(\"\\n========== LOCALITY-LEVEL PRICE DRIFT ==========\\n\")\n",
    "\n",
    "        train_loc_means = train.groupby(\"locality_name\")[\"price\"].mean()\n",
    "        test_loc_means = test.groupby(\"locality_name\")[\"price\"].mean()\n",
    "\n",
    "        print(\"\\nTrain locality price mean distribution:\")\n",
    "        print(train_loc_means.describe())\n",
    "\n",
    "        print(\"\\nTest locality price mean distribution:\")\n",
    "        print(test_loc_means.describe())\n",
    "\n",
    "        # common localities only\n",
    "        common = list(set(train_loc_means.index) & set(test_loc_means.index))\n",
    "\n",
    "        paired_train = train_loc_means.loc[common]\n",
    "        paired_test = test_loc_means.loc[common]\n",
    "\n",
    "        stat, p = ks_2samp(paired_train, paired_test)\n",
    "\n",
    "        print(\"\\nLocality-level KS test (common localities):\")\n",
    "        print(f\"KS statistic: {stat:.4f}\")\n",
    "        print(f\"P-value     : {p:.6f}\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\" DRIFT ANALYSIS COMPLETE\")\n",
    "    print(\"==============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "324dbd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 23)\n",
      "Test: (2875, 23)\n",
      "Train after outlier removal: (9169, 23)\n",
      "\n",
      "==============================\n",
      " DRIFT ANALYSIS STARTING\n",
      "==============================\n",
      "\n",
      "Numeric columns: ['build_year', 'facades', 'living_area', 'number_rooms', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'garden_flag', 'terrace_flag', 'swimming_pool_flag', 'postal_prefix', 'postal_code_num', 'price']\n",
      "Categorical columns: ['garden', 'locality_name', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n",
      "\n",
      "========== CHECKING CATEGORY COVERAGE ==========\n",
      "\n",
      "\n",
      "=== CATEGORY COVERAGE: garden ===\n",
      "Unique in train: 2\n",
      "Unique in test:  2\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: locality_name ===\n",
      "Unique in train: 51\n",
      "Unique in test:  51\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: postal_code ===\n",
      "Unique in train: 779\n",
      "Unique in test:  573\n",
      "Present in TEST but NOT in train (unseen categories): 41\n",
      "Examples: ['9112.0', '6010.0', '8820.0', '7618.0', '6741.0', '3061.0', '3631.0', '2243.0', '7180.0', '8211.0', '6856.0', '6812.0', '7740.0', '3798.0', '5501.0']\n",
      "Present in TRAIN but NOT in test: 247\n",
      "\n",
      "=== CATEGORY COVERAGE: property_type ===\n",
      "Unique in train: 15\n",
      "Unique in test:  18\n",
      "Present in TEST but NOT in train (unseen categories): 4\n",
      "Examples: ['Commercial', 'Land', 'Development', 'Mansion']\n",
      "Present in TRAIN but NOT in test: 1\n",
      "\n",
      "=== CATEGORY COVERAGE: state ===\n",
      "Unique in train: 9\n",
      "Unique in test:  9\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: swimming_pool ===\n",
      "Unique in train: 2\n",
      "Unique in test:  2\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: terrace ===\n",
      "Unique in train: 2\n",
      "Unique in test:  2\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: province ===\n",
      "Unique in train: 11\n",
      "Unique in test:  11\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: region ===\n",
      "Unique in train: 3\n",
      "Unique in test:  3\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "========== KS-TEST FOR NUMERICAL FEATURES ==========\n",
      "\n",
      "\n",
      "=== KS TEST: build_year ===\n",
      "KS statistic: 0.0207\n",
      "P-value     : 0.826610\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: facades ===\n",
      "KS statistic: 0.0174\n",
      "P-value     : 0.751306\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: living_area ===\n",
      "KS statistic: 0.0601\n",
      "P-value     : 0.000001\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: number_rooms ===\n",
      "KS statistic: 0.0515\n",
      "P-value     : 0.000037\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: house_age ===\n",
      "KS statistic: 0.0178\n",
      "P-value     : 0.953652\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: is_new_build ===\n",
      "KS statistic: 0.0049\n",
      "P-value     : 1.000000\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: is_recent ===\n",
      "KS statistic: 0.0032\n",
      "P-value     : 1.000000\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: is_old ===\n",
      "KS statistic: 0.0087\n",
      "P-value     : 0.995786\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: build_decade ===\n",
      "KS statistic: 0.0190\n",
      "P-value     : 0.895965\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: garden_flag ===\n",
      "KS statistic: 0.0308\n",
      "P-value     : 0.030269\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: terrace_flag ===\n",
      "KS statistic: 0.0105\n",
      "P-value     : 0.976868\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: swimming_pool_flag ===\n",
      "KS statistic: 0.0097\n",
      "P-value     : 0.985523\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: postal_prefix ===\n",
      "KS statistic: 0.0372\n",
      "P-value     : 0.004534\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: postal_code_num ===\n",
      "KS statistic: 0.0385\n",
      "P-value     : 0.002953\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: price ===\n",
      "KS statistic: 0.0791\n",
      "P-value     : 0.000000\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "========== TARGET DRIFT (PRICE DISTRIBUTION) ==========\n",
      "\n",
      "Train price stats:\n",
      "count      9169.000000\n",
      "mean     333646.379213\n",
      "std      125889.858860\n",
      "min       25000.000000\n",
      "25%      246010.000000\n",
      "50%      319000.000000\n",
      "75%      404000.000000\n",
      "max      725000.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Test price stats:\n",
      "count    2.875000e+03\n",
      "mean     3.883394e+05\n",
      "std      2.525057e+05\n",
      "min      2.000000e+04\n",
      "25%      2.499500e+05\n",
      "50%      3.290000e+05\n",
      "75%      4.450000e+05\n",
      "max      2.915000e+06\n",
      "Name: price, dtype: float64\n",
      "\n",
      "========== LOCALITY-LEVEL PRICE DRIFT ==========\n",
      "\n",
      "\n",
      "Train locality price mean distribution:\n",
      "count        51.000000\n",
      "mean     342485.271854\n",
      "std       66647.838628\n",
      "min      230405.870968\n",
      "25%      290109.259091\n",
      "50%      336073.256410\n",
      "75%      377670.468750\n",
      "max      561446.428571\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Test locality price mean distribution:\n",
      "count        51.000000\n",
      "mean     390477.465638\n",
      "std      132206.310891\n",
      "min      220100.647059\n",
      "25%      311629.033333\n",
      "50%      361726.666667\n",
      "75%      419039.177489\n",
      "max      757777.777778\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Locality-level KS test (common localities):\n",
      "KS statistic: 0.2157\n",
      "P-value     : 0.187282\n",
      "\n",
      "==============================\n",
      " DRIFT ANALYSIS COMPLETE\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_clean, X_test, y_train_clean, y_test, preprocessor = run_preprocessing_pipeline(\n",
    "    path=\"data/processed/cleaned_v2.csv\"\n",
    ")\n",
    "\n",
    "drift_check(X_train_clean, X_test, y_train_clean, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd43a3",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "170c0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Train/Test Split (80/20)\n",
    "# -------------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Outlier removal (train only)\n",
    "# -------------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    # IQR filter on price and living_area\n",
    "    def iqr_filter(df, col):\n",
    "        if col not in df.columns:\n",
    "            return df\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    for col in [\"price\", \"living_area\"]:\n",
    "        df_train = iqr_filter(df_train, col)\n",
    "\n",
    "    # Rooms sanity filter\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Train after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Preprocessor\n",
    "# -------------------------------------------------------------\n",
    "def build_preprocessor(X):\n",
    "    numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\", \"Int64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Postal code must be categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"Numeric:\", numeric_cols)\n",
    "    print(\"Categorical:\", categorical_cols)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Evaluate helper\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_rf(model, X, y, split_name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": split_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Train RF\n",
    "# -------------------------------------------------------------\n",
    "def train_random_forest(X_train, y_train, preprocessor):\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\nRandom Forest model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Full RF workflow (Train/Test only)\n",
    "# -------------------------------------------------------------\n",
    "def run_random_forest_no_val(df):\n",
    "\n",
    "    # Split DF\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    # Outliers from train only\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    # Train model\n",
    "    model = train_random_forest(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    results = []\n",
    "    results.append(evaluate_rf(model, X_train_clean, y_train_clean, \"Train\"))\n",
    "    results.append(evaluate_rf(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/random_forest_no_val.pkl\")\n",
    "    print(\"\\nModel saved to models/random_forest_no_val.pkl\")\n",
    "\n",
    "    return model, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e3a7717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 20)\n",
      "Test: (2875, 20)\n",
      "Train after outlier removal: (9169, 20)\n",
      "Numeric: ['build_year', 'facades', 'living_area', 'number_rooms', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'garden_flag', 'terrace_flag', 'swimming_pool_flag']\n",
      "Categorical: ['garden', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n",
      "\n",
      "Random Forest model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  17,538.70\n",
      "RMSE: 25,588.66\n",
      "R²:   0.9587\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  92,433.16\n",
      "RMSE: 210,496.94\n",
      "R²:   0.3048\n",
      "\n",
      "Model saved to models/random_forest_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "706b861c-e791-4e3d-bdcf-5153cb5818c8",
       "rows": [
        [
         "0",
         "Train",
         "17538.69577904418",
         "25588.659985467657",
         "0.9586799382433148"
        ],
        [
         "1",
         "Test",
         "92433.15750902316",
         "210496.94468279078",
         "0.30481503960231415"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>17538.695779</td>\n",
       "      <td>25588.659985</td>\n",
       "      <td>0.958680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>92433.157509</td>\n",
       "      <td>210496.944683</td>\n",
       "      <td>0.304815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  17538.695779   25588.659985  0.958680\n",
       "1   Test  92433.157509  210496.944683  0.304815"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run\n",
    "df = pd.read_csv(\"data/processed/feature_engineered.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "rf_model, rf_results = run_random_forest_no_val(df)\n",
    "rf_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ef054",
   "metadata": {},
   "source": [
    "### Function to train a Random Forest with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5269645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Train/Test Split (80/20)\n",
    "# -------------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Outlier removal (train only)\n",
    "# -------------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    # IQR filter on price and living_area\n",
    "    def iqr_filter(df, col):\n",
    "        if col not in df.columns:\n",
    "            return df\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    for col in [\"price\", \"living_area\"]:\n",
    "        df_train = iqr_filter(df_train, col)\n",
    "\n",
    "    # Rooms sanity filter\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Train after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Preprocessor\n",
    "# -------------------------------------------------------------\n",
    "def build_preprocessor(X):\n",
    "    numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\", \"Int64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Postal code must be categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"Numeric:\", numeric_cols)\n",
    "    print(\"Categorical:\", categorical_cols)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Evaluate helper\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_rf(model, X, y, split_name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": split_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Train RF\n",
    "# -------------------------------------------------------------\n",
    "def train_random_forest(X_train, y_train, preprocessor):\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\nRandom Forest model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Full RF workflow (Train/Test only)\n",
    "# -------------------------------------------------------------\n",
    "def run_random_forest_no_val(df):\n",
    "\n",
    "    # Split DF\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    # Outliers from train only\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    # Train model\n",
    "    model = train_random_forest(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    results = []\n",
    "    results.append(evaluate_rf(model, X_train_clean, y_train_clean, \"Train\"))\n",
    "    results.append(evaluate_rf(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/random_forest_no_val.pkl\")\n",
    "    print(\"\\nModel saved to models/random_forest_no_val.pkl\")\n",
    "\n",
    "    return model, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ee159",
   "metadata": {},
   "source": [
    "### RUN random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "775d0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 11)\n",
      "Test: (2875, 11)\n",
      "Train after outlier removal: (9169, 11)\n",
      "Numeric: ['build_year', 'facades', 'living_area', 'number_rooms']\n",
      "Categorical: ['garden', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province']\n",
      "\n",
      "Random Forest model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  17,368.61\n",
      "RMSE: 25,312.89\n",
      "R²:   0.9596\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  90,827.02\n",
      "RMSE: 208,240.82\n",
      "R²:   0.3196\n",
      "\n",
      "Model saved to models/random_forest_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "87ccf9c7-5748-4146-9de5-83a6b538f985",
       "rows": [
        [
         "0",
         "Train",
         "17368.60860907068",
         "25312.89121232616",
         "0.9595657510998237"
        ],
        [
         "1",
         "Test",
         "90827.01832204277",
         "208240.82414692367",
         "0.3196372580058163"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>17368.608609</td>\n",
       "      <td>25312.891212</td>\n",
       "      <td>0.959566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>90827.018322</td>\n",
       "      <td>208240.824147</td>\n",
       "      <td>0.319637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  17368.608609   25312.891212  0.959566\n",
       "1   Test  90827.018322  208240.824147  0.319637"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "rf_model, rf_results = run_random_forest_no_val(df)\n",
    "rf_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570ec8e",
   "metadata": {},
   "source": [
    "## Tuned Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4f16c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 1) Quick train/test split (80/20)\n",
    "#----------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test :\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 2) Outlier removal (train only)\n",
    "#----------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    if \"living_area\" in df_train.columns:\n",
    "        Q1, Q3 = df_train[\"living_area\"].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_train = df_train[(df_train[\"living_area\"] >= lower) & (df_train[\"living_area\"] <= upper)]\n",
    "\n",
    "    df_train = df_train[df_train[\"price\"] >= 10000]\n",
    "\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y = df_train[\"price\"]\n",
    "    X = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Train after outlier removal:\", X.shape)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 3) Safe preprocessor\n",
    "#----------------------------------------------------------\n",
    "def build_preprocessor(X_train):\n",
    "\n",
    "    numeric_cols = X_train.select_dtypes(include=[\"float64\",\"int64\",\"Int64\"]).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=[\"object\",\"string\"]).columns.tolist()\n",
    "\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    # Limit one-hot explosion\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", min_frequency=50)\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", encoder)\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 4) Safe evaluation\n",
    "#----------------------------------------------------------\n",
    "def evaluate_split(model, X, y, split_name):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R2:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": split_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 5) Random Forest tuning (safe)\n",
    "#----------------------------------------------------------\n",
    "def train_random_forest_tuned(X_train, y_train, preprocessor):\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # SAFE small grid (won’t crash)\n",
    "    param_grid = {\n",
    "        \"model__n_estimators\": [200, 300],\n",
    "        \"model__max_depth\": [10, 20, 30],\n",
    "        \"model__max_features\": [0.3, 0.5, \"sqrt\"],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,          # small search\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=3,\n",
    "        n_jobs=1,           # IMPORTANT: prevents kernel crash\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest params:\", search.best_params_)\n",
    "    return search.best_estimator_\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 6) Full workflow (No validation)\n",
    "#----------------------------------------------------------\n",
    "def run_random_forest_tuned_no_val(df):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    model = train_random_forest_tuned(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    train_res = evaluate_split(model, X_train_clean, y_train_clean, \"Train\")\n",
    "    test_res = evaluate_split(model, X_test, y_test, \"Test\")\n",
    "\n",
    "    results = pd.DataFrame([train_res, test_res])\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/random_forest_tuned_no_val.pkl\")\n",
    "\n",
    "    print(\"\\nModel saved to models/random_forest_tuned_no_val.pkl\")\n",
    "\n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cea288",
   "metadata": {},
   "source": [
    "## Run random forest tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e342408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 24)\n",
      "Test : (2875, 24)\n",
      "Train after outlier removal: (9675, 24)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best params: {'model__n_estimators': 200, 'model__min_samples_split': 5, 'model__min_samples_leaf': 1, 'model__max_features': 0.3, 'model__max_depth': 30}\n",
      "\n",
      "--- Train ---\n",
      "MAE:  30,099.19\n",
      "RMSE: 53,884.69\n",
      "R2:   0.9153\n",
      "\n",
      "--- Test ---\n",
      "MAE:  81,187.41\n",
      "RMSE: 180,581.62\n",
      "R2:   0.4884\n",
      "\n",
      "Model saved to models/random_forest_tuned_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f46491fb-10ac-458b-89fe-e8e8b52c60ce",
       "rows": [
        [
         "0",
         "Train",
         "30099.191413556433",
         "53884.68512022465",
         "0.9153396106788401"
        ],
        [
         "1",
         "Test",
         "81187.40910309154",
         "180581.62328589603",
         "0.4883701432337465"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>30099.191414</td>\n",
       "      <td>53884.685120</td>\n",
       "      <td>0.91534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>81187.409103</td>\n",
       "      <td>180581.623286</td>\n",
       "      <td>0.48837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE       R2\n",
       "0  Train  30099.191414   53884.685120  0.91534\n",
       "1   Test  81187.409103  180581.623286  0.48837"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/feature_engineered.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "rf_tuned_model, rf_tuned_results = run_random_forest_tuned_no_val(df)\n",
    "rf_tuned_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9f9b6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3377ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. BUILD PREPROCESSOR\n",
    "# ============================================================\n",
    "def build_preprocessor(df):\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\", \"Int64\"]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Postal code must remain categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. TRAIN XGBOOST (NO VALIDATION SET)\n",
    "# ============================================================\n",
    "def train_xgboost_no_val(X_train, y_train, preprocessor):\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"XGBoost model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. EVALUATE MODEL\n",
    "# ============================================================\n",
    "def evaluate(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. FULL WORKFLOW (80/20 TRAIN-TEST)\n",
    "# ============================================================\n",
    "def run_xgboost_no_val(df):\n",
    "\n",
    "    # --- enforce correct dtype ---\n",
    "    df[\"postal_code\"] = df[\"postal_code\"].astype(\"string\")\n",
    "\n",
    "    # --- split 80/20 ---\n",
    "    X = df.drop(columns=[\"price\"])\n",
    "    y = df[\"price\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    # --- build preprocessor ---\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "\n",
    "    # --- train model ---\n",
    "    model = train_xgboost_no_val(X_train, y_train, preprocessor)\n",
    "\n",
    "    # --- evaluate ---\n",
    "    results = []\n",
    "    results.append(evaluate(model, X_train, y_train, \"Train\"))\n",
    "    results.append(evaluate(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # --- save model ---\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/xgboost_no_val.pkl\")\n",
    "\n",
    "    print(\"\\nXGBoost (No Validation) saved to models/xgboost_no_val.pkl\")\n",
    "\n",
    "    return model, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fce7ff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 20)\n",
      "Test: (2875, 20)\n",
      "XGBoost model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  60,808.20\n",
      "RMSE: 94,950.97\n",
      "R²:   0.8735\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  76,492.30\n",
      "RMSE: 143,854.95\n",
      "R²:   0.6753\n",
      "\n",
      "XGBoost (No Validation) saved to models/xgboost_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9f35246d-4091-4d80-ab45-7e84ead13e48",
       "rows": [
        [
         "0",
         "Train",
         "60808.20323557348",
         "94950.97273609738",
         "0.8734528584930509"
        ],
        [
         "1",
         "Test",
         "76492.30378328804",
         "143854.94986786955",
         "0.6753178635643704"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>60808.203236</td>\n",
       "      <td>94950.972736</td>\n",
       "      <td>0.873453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>76492.303783</td>\n",
       "      <td>143854.949868</td>\n",
       "      <td>0.675318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  60808.203236   94950.972736  0.873453\n",
       "1   Test  76492.303783  143854.949868  0.675318"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/feature_engineered.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "xgb_model, xgb_results = run_xgboost_no_val(df)\n",
    "xgb_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f230eff",
   "metadata": {},
   "source": [
    "### Run XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070a7d6",
   "metadata": {},
   "source": [
    "## Tuned XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1270b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Split into 80% train / 20% test\n",
    "# ---------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Evaluate helper\n",
    "# ---------------------------------------------------------\n",
    "def evaluate_split(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Train XGBoost with Hyperparameter Tuning (NO VAL)\n",
    "# ---------------------------------------------------------\n",
    "def train_xgboost_tuned_no_val(X_train, y_train, preprocessor):\n",
    "\n",
    "    # Define default model\n",
    "    base_xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        booster=\"gbtree\",\n",
    "        eval_metric=\"rmse\",\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", base_xgb)\n",
    "    ])\n",
    "\n",
    "    # Parameter grid (lightweight for Windows)\n",
    "    param_dist = {\n",
    "    \"model__n_estimators\": [200, 300],\n",
    "    \"model__learning_rate\": [0.03, 0.07],\n",
    "    \"model__max_depth\": [3, 4],\n",
    "    \"model__subsample\": [0.8],\n",
    "    \"model__colsample_bytree\": [0.8]\n",
    "    }\n",
    "\n",
    "    print(\"\\nStarting RandomizedSearchCV for XGBoost...\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=3,\n",
    "        n_jobs=1,             # IMPORTANT: fixes BrokenProcessPool\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    return search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Full workflow (train + test)\n",
    "# ---------------------------------------------------------\n",
    "def run_xgboost_tuned_no_val(df, preprocessor):\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    # Train tuned model\n",
    "    model = train_xgboost_tuned_no_val(X_train, y_train, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    results = []\n",
    "    results.append(evaluate_split(model, X_train, y_train, \"Train\"))\n",
    "    results.append(evaluate_split(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    # Save\n",
    "    joblib.dump(model, \"models/xgboost_tuned_no_val.pkl\")\n",
    "    print(\"\\nXGBoost (Tuned, No Validation) saved to models/xgboost_tuned_no_val.pkl\")\n",
    "\n",
    "    return model, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cbbe27b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 20)\n",
      "Test: (2875, 20)\n",
      "\n",
      "Starting RandomizedSearchCV for XGBoost...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'model__subsample': 0.8, 'model__n_estimators': 300, 'model__max_depth': 4, 'model__learning_rate': 0.07, 'model__colsample_bytree': 0.8}\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  73,800.37\n",
      "RMSE: 121,079.57\n",
      "R²:   0.7942\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  82,378.67\n",
      "RMSE: 151,429.23\n",
      "R²:   0.6402\n",
      "\n",
      "XGBoost (Tuned, No Validation) saved to models/xgboost_tuned_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7eeb5d90-c602-44e5-af6c-34db7eb6fc76",
       "rows": [
        [
         "0",
         "Train",
         "73800.36568074534",
         "121079.56882080465",
         "0.7942237566529724"
        ],
        [
         "1",
         "Test",
         "82378.66725195313",
         "151429.2291909757",
         "0.6402273058663226"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>73800.365681</td>\n",
       "      <td>121079.568821</td>\n",
       "      <td>0.794224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>82378.667252</td>\n",
       "      <td>151429.229191</td>\n",
       "      <td>0.640227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  73800.365681  121079.568821  0.794224\n",
       "1   Test  82378.667252  151429.229191  0.640227"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/feature_engineered.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "# Build preprocessor correctly\n",
    "preprocessor = build_preprocessor(df.drop(columns=[\"price\"]))\n",
    "\n",
    "# Run tuned XGBoost\n",
    "xgb_model, xgb_results = run_xgboost_tuned_no_val(df, preprocessor)\n",
    "\n",
    "xgb_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b2a6a",
   "metadata": {},
   "source": [
    "## LOG-TRANSFORMED XGBOOST TRAINING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a03451e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_xgboost_log_target(\n",
    "        df,\n",
    "        target=\"price\",\n",
    "        save_path=\"models/xgboost_log_model.pkl\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    XGBoost Pipeline with Log-Transformed Target.\n",
    "    \n",
    "    Steps:\n",
    "    - removes missing price\n",
    "    - train/test split\n",
    "    - log1p transform on target\n",
    "    - OneHotEncoder (categorical) + passthrough (numerical)\n",
    "    - XGBoost model\n",
    "    - exponentiate predictions back to EUR\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 1. Remove missing target\n",
    "    # ------------------------------------------\n",
    "    df = df[df[target].notna()].copy()\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 2. Split dataset\n",
    "    # ------------------------------------------\n",
    "    X = df.drop(columns=[target])\n",
    "    y = np.log1p(df[target])   # LOG transform\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 3. Column types\n",
    "    # ------------------------------------------\n",
    "    cat_cols = X_train.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "    num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ])\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 4. XGBoost Model\n",
    "    # ------------------------------------------\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 5. Fit Model\n",
    "    # ------------------------------------------\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 6. Predict (exponentiate back to EUR)\n",
    "    # ------------------------------------------\n",
    "    train_preds = np.expm1(pipe.predict(X_train))\n",
    "    test_preds  = np.expm1(pipe.predict(X_test))\n",
    "\n",
    "    y_train_real = np.expm1(y_train)\n",
    "    y_test_real  = np.expm1(y_test)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 7. Metrics\n",
    "    # ------------------------------------------\n",
    "    results = {\n",
    "        \"Train MAE\": mean_absolute_error(y_train_real, train_preds),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train_real, train_preds)),\n",
    "        \"Train R2\": r2_score(y_train_real, train_preds),\n",
    "\n",
    "        \"Test MAE\": mean_absolute_error(y_test_real, test_preds),\n",
    "        \"Test RMSE\": np.sqrt(mean_squared_error(y_test_real, test_preds)),\n",
    "        \"Test R2\": r2_score(y_test_real, test_preds)\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 8. Save model\n",
    "    # ------------------------------------------\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    joblib.dump(pipe, save_path)\n",
    "\n",
    "    print(\"Model saved to:\", save_path)\n",
    "    print(\"\\n===== XGBoost (Log Target) Results =====\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k}: {v:,.2f}\")\n",
    "\n",
    "    return pipe, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16aabbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: models/xgboost_log_model.pkl\n",
      "\n",
      "===== XGBoost (Log Target) Results =====\n",
      "Train MAE: 71,153.50\n",
      "Train RMSE: 145,360.82\n",
      "Train R2: 0.70\n",
      "Test MAE: 75,870.23\n",
      "Test RMSE: 149,351.96\n",
      "Test R2: 0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train MAE': 71153.50031694332,\n",
       " 'Train RMSE': np.float64(145360.82230481753),\n",
       " 'Train R2': 0.7034156400423359,\n",
       " 'Test MAE': 75870.22748641304,\n",
       " 'Test RMSE': np.float64(149351.96133388623),\n",
       " 'Test R2': 0.6500301466738249}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/feature_engineered.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "model, metrics = train_xgboost_log_target(df)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3dc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68abfafd",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "926a6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BUILD PREPROCESSOR\n",
    "# ------------------------------------------------------------\n",
    "def build_preprocessor(df):\n",
    "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Make sure postal_code is categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CROSS VALIDATION FUNCTION\n",
    "# ------------------------------------------------------------\n",
    "def run_cross_validation(df, target=\"price\"):\n",
    "    # Split features/target\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = build_preprocessor(X)\n",
    "\n",
    "    # Model pipeline\n",
    "    model = Pipeline([\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"xgb\", XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=8,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Metrics\n",
    "    scorers = {\n",
    "        \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        \"RMSE\": make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)),\n",
    "                            greater_is_better=False),\n",
    "        \"R2\": make_scorer(r2_score)\n",
    "    }\n",
    "\n",
    "    # CV split\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Evaluate\n",
    "    results = cross_validate(\n",
    "        model,\n",
    "        X, y,\n",
    "        scoring=scorers,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    print(\"\\nCROSS VALIDATION RESULTS (5-FOLD)\")\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"MAE :\", -results[\"test_MAE\"].mean())\n",
    "    print(\"RMSE:\", -results[\"test_RMSE\"].mean())\n",
    "    print(\"R²  :\", results[\"test_R2\"].mean())\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58ced687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CROSS VALIDATION RESULTS (5-FOLD)\n",
      "----------------------------------\n",
      "MAE : 75769.87637568748\n",
      "RMSE: 152483.7902251448\n",
      "R²  : 0.6661841873221889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "# Run CV\n",
    "cv_results = run_cross_validation(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc7fd8",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2261a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train-only outlier removal\n",
    "# ------------------------------------------------------------\n",
    "def remove_train_outliers(X_train, y_train, columns=None, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Removes outliers from TRAIN ONLY (IQR filtering).\n",
    "    Avoids test leakage.\n",
    "    \"\"\"\n",
    "    df = X_train.copy()\n",
    "    df[\"price\"] = y_train\n",
    "\n",
    "    if columns is None:\n",
    "        columns = [\"price\", \"living_area\", \"number_rooms\"]\n",
    "\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        series = df[col].dropna()\n",
    "        if len(series) < 100:\n",
    "            continue\n",
    "\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower = Q1 - multiplier * IQR\n",
    "        upper = Q3 + multiplier * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    y_clean = df[\"price\"]\n",
    "    X_clean = df.drop(columns=[\"price\"])\n",
    "    return X_clean, y_clean\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Group-based split\n",
    "# ------------------------------------------------------------\n",
    "def group_split(df, group_col=\"locality_name\", test_size=0.20):\n",
    "    splitter = GroupShuffleSplit(\n",
    "        test_size=test_size,\n",
    "        n_splits=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    groups = df[group_col]\n",
    "    train_idx, test_idx = next(splitter.split(df, groups=groups))\n",
    "\n",
    "    train = df.iloc[train_idx].copy()\n",
    "    test = df.iloc[test_idx].copy()\n",
    "\n",
    "    print(\"Train:\", train.shape)\n",
    "    print(\"Test :\", test.shape)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FINAL XGBoost Training Function\n",
    "# ------------------------------------------------------------\n",
    "def train_xgboost(df, target=\"price\", save_path=\"models/xgboost_geo_tuned.pkl\"):\n",
    "\n",
    "    # 1. Split (geospatial)\n",
    "    train_df, test_df = group_split(df, \"locality_name\")\n",
    "\n",
    "    # 2. Log target\n",
    "    y_train = np.log1p(train_df[target])\n",
    "    y_test = np.log1p(test_df[target])\n",
    "\n",
    "    X_train = train_df.drop(columns=[target])\n",
    "    X_test = test_df.drop(columns=[target])\n",
    "\n",
    "    # 3. TRAIN-ONLY outlier removal\n",
    "    X_train, y_train = remove_train_outliers(\n",
    "        X_train, y_train,\n",
    "        columns=[\"price\", \"living_area\", \"number_rooms\"]\n",
    "    )\n",
    "    print(\"Train after outlier removal:\", X_train.shape)\n",
    "\n",
    "    # 4. Identify column types\n",
    "    cat_cols = X_train.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "    num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    print(\"\\nCategorical:\", cat_cols)\n",
    "    print(\"Numeric:\", num_cols)\n",
    "\n",
    "    # 5. Preprocessing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ])\n",
    "\n",
    "    # 6. XGBoost model\n",
    "    model = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    param_dist = {\n",
    "        \"model__max_depth\": [4, 6, 8],\n",
    "        \"model__learning_rate\": [0.03, 0.05, 0.1],\n",
    "        \"model__n_estimators\": [300, 600, 900],\n",
    "        \"model__subsample\": [0.7, 0.8, 1.0],\n",
    "        \"model__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"model__min_child_weight\": [1, 5, 10],\n",
    "        \"model__gamma\": [0, 1, 5],\n",
    "        \"model__reg_lambda\": [1, 3, 5]\n",
    "    }\n",
    "\n",
    "    print(\"\\nTuning XGBoost hyperparameters...\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        cv=3,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(\"\\nBest hyperparameters:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # 7. Evaluate\n",
    "    preds_train = np.expm1(best_model.predict(X_train))\n",
    "    preds_test = np.expm1(best_model.predict(X_test))\n",
    "\n",
    "    mae_train = mean_absolute_error(train_df[target], preds_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(train_df[target], preds_train))\n",
    "    r2_train = r2_score(train_df[target], preds_train)\n",
    "\n",
    "    mae_test = mean_absolute_error(test_df[target], preds_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(test_df[target], preds_test))\n",
    "    r2_test = r2_score(test_df[target], preds_test)\n",
    "\n",
    "    print(\"\\n===== FINAL XGBOOST RESULTS =====\")\n",
    "    print(\"\\n--- Train ---\")\n",
    "    print(f\"MAE:  {mae_train:,.2f}\")\n",
    "    print(f\"RMSE: {rmse_train:,.2f}\")\n",
    "    print(f\"R²:   {r2_train:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Test ---\")\n",
    "    print(f\"MAE:  {mae_test:,.2f}\")\n",
    "    print(f\"RMSE: {rmse_test:,.2f}\")\n",
    "    print(f\"R²:   {r2_test:.4f}\")\n",
    "\n",
    "    # 8. Save\n",
    "    joblib.dump(best_model, save_path)\n",
    "    print(f\"\\nSaved model to: {save_path}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b41a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11511, 18)\n",
      "Test: (2878, 18)\n",
      "\n",
      "Numeric columns: ['build_year', 'facades', 'living_area', 'number_rooms', 'swimming_pool', 'terrace', 'has_garden']\n",
      "Categorical columns: ['locality_name', 'postal_code', 'property_id', 'property_type', 'property_url', 'state', 'province', 'property_type_name', 'state_mapped', 'region']\n",
      "XGBoost model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  60,358.44\n",
      "RMSE: 86,530.08\n",
      "R²:   0.9030\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  77,210.48\n",
      "RMSE: 139,893.22\n",
      "R²:   0.6928\n",
      "\n",
      "XGBoost (No Validation) saved to models/xgboost_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "057d4c75-20ce-448e-8d26-e47a681cdff2",
       "rows": [
        [
         "0",
         "Train",
         "60358.43964740248",
         "86530.08194912798",
         "0.9030109660520834"
        ],
        [
         "1",
         "Test",
         "77210.47963266591",
         "139893.21560040285",
         "0.6927964716501656"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>60358.439647</td>\n",
       "      <td>86530.081949</td>\n",
       "      <td>0.903011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>77210.479633</td>\n",
       "      <td>139893.215600</td>\n",
       "      <td>0.692796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  60358.439647   86530.081949  0.903011\n",
       "1   Test  77210.479633  139893.215600  0.692796"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "xgb_model, xgb_results = run_xgboost_no_val(df)\n",
    "xgb_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
