{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed399160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cleaned data: (14375, 15)\n",
      "Train: (8625, 14)\n",
      "Validation: (2875, 14)\n",
      "Test: (2875, 14)\n",
      "Training after outlier removal: (6915, 14)\n",
      "Numeric columns: ['build_year', 'facades', 'living_area', 'number_rooms', 'postal_code']\n",
      "Categorical columns: ['garden', 'locality_name', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'property_type_name', 'state_mapped']\n",
      "\n",
      "Training model: LinearRegression\n",
      "\n",
      "Training model: RandomForest\n",
      "\n",
      "Training model: XGBoost\n",
      "\n",
      "Model comparison (MAE, RMSE, R2):\n",
      "              Model       Split       MAE       RMSE      R2\n",
      "2  LinearRegression        Test  95775.96  213772.65  0.3824\n",
      "5      RandomForest        Test  92281.81  226754.82  0.3052\n",
      "8           XGBoost        Test  90599.93  218969.94  0.3520\n",
      "0  LinearRegression       Train  45057.90   63861.97  0.7489\n",
      "3      RandomForest       Train  17319.19   25256.01  0.9607\n",
      "6           XGBoost       Train  37818.86   50996.55  0.8399\n",
      "1  LinearRegression  Validation  87943.62  170357.72  0.4631\n",
      "4      RandomForest  Validation  84433.36  182824.86  0.3816\n",
      "7           XGBoost  Validation  82988.79  175505.69  0.4301\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "os.chdir(r\"C:\\Users\\welde\\Desktop\\immo-eliza-ml\") \n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load cleaned data (already dtype-cleaned by your function)\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(\"data/processed/dtype_cleaned.csv\")\n",
    "print(\"Loaded cleaned data:\", df.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Split into train / validation / test (60 / 20 / 20)\n",
    "# ------------------------------------------------------------\n",
    "def split_data(df, target=\"price\"):\n",
    "    \"\"\"\n",
    "    Split data into train / validation / test using 60 / 20 / 20 ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # 60% train, 40% temp\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.40, random_state=42\n",
    "    )\n",
    "\n",
    "    # 20% val, 20% test from temp\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.50, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Validation:\", X_val.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Remove outliers ONLY from training set\n",
    "# ------------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Remove outliers from training data only, to avoid data leakage.\n",
    "    - IQR-based filtering on price and living_area\n",
    "    - Logical cap on number_rooms (<= 12)\n",
    "    \"\"\"\n",
    "\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    def iqr_filter(df, col):\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    # Apply IQR filtering\n",
    "    if \"price\" in df_train.columns:\n",
    "        df_train = iqr_filter(df_train, \"price\")\n",
    "\n",
    "    if \"living_area\" in df_train.columns:\n",
    "        df_train = iqr_filter(df_train, \"living_area\")\n",
    "\n",
    "    # Logical constraint on number of rooms\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    # Separate back X and y\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Training after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Build preprocessing transformer\n",
    "# ------------------------------------------------------------\n",
    "def build_preprocessor(X_train):\n",
    "    \"\"\"\n",
    "    Build a ColumnTransformer that:\n",
    "    - imputes and scales numeric features\n",
    "    - imputes and one-hot encodes categorical features\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_cols = X_train.select_dtypes(\n",
    "        include=[\"float64\", \"int64\", \"Int64\"]\n",
    "    ).columns.tolist()\n",
    "\n",
    "    categorical_cols = X_train.select_dtypes(\n",
    "        include=[\"object\", \"string\"]\n",
    "    ).columns.tolist()\n",
    "\n",
    "    numeric_pipeline = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipeline, numeric_cols),\n",
    "            (\"cat\", categorical_pipeline, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Numeric columns:\", numeric_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Evaluation helper\n",
    "# ------------------------------------------------------------\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"\n",
    "    Compute MAE, RMSE, RÂ² for a model on given data.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Train and evaluate all 3 models\n",
    "# ------------------------------------------------------------\n",
    "def compare_models(df):\n",
    "    \"\"\"\n",
    "    Full workflow:\n",
    "      - split data\n",
    "      - clean training outliers\n",
    "      - build preprocessor\n",
    "      - train Linear Regression, Random Forest, XGBoost\n",
    "      - evaluate each on train / val / test\n",
    "      - return comparison table\n",
    "    \"\"\"\n",
    "\n",
    "    # Split\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "\n",
    "    # Outlier removal on training only\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Preprocessor based on cleaned training data\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    # Define the three models\n",
    "    models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForest\": RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"XGBoost\": XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            n_estimators=400,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            reg_alpha=0.0,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            tree_method=\"hist\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Loop over each model\n",
    "    for name, estimator in models.items():\n",
    "        print(f\"\\nTraining model: {name}\")\n",
    "\n",
    "        # Build a fresh pipeline for each model\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", estimator)\n",
    "        ])\n",
    "\n",
    "        # Fit on cleaned training data\n",
    "        model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "        # Evaluate on train, val, test\n",
    "        for split_name, X_split, y_split in [\n",
    "            (\"Train\", X_train_clean, y_train_clean),\n",
    "            (\"Validation\", X_val, y_val),\n",
    "            (\"Test\", X_test, y_test),\n",
    "        ]:\n",
    "            mae, rmse, r2 = evaluate_model(model, X_split, y_split)\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Split\": split_name,\n",
    "                \"MAE\": mae,\n",
    "                \"RMSE\": rmse,\n",
    "                \"R2\": r2\n",
    "            })\n",
    "\n",
    "    # Build a DataFrame with all results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Nice sorting: by Split, then Model\n",
    "    results_df = results_df.sort_values(by=[\"Split\", \"Model\"])\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Run comparison and inspect results\n",
    "# ------------------------------------------------------------\n",
    "comparison_df = compare_models(df)\n",
    "\n",
    "# Print nicely with rounded metrics\n",
    "comparison_display = comparison_df.copy()\n",
    "comparison_display[\"MAE\"] = comparison_display[\"MAE\"].round(2)\n",
    "comparison_display[\"RMSE\"] = comparison_display[\"RMSE\"].round(2)\n",
    "comparison_display[\"R2\"] = comparison_display[\"R2\"].round(4)\n",
    "\n",
    "print(\"\\nModel comparison (MAE, RMSE, R2):\")\n",
    "print(comparison_display)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
