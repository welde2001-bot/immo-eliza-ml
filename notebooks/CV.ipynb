{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579d78c3",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed399160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# ---------- Custom transformer: outlier trimming learned on each training fold ----------\n",
    "class IQRTrimmer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Trims rows based on IQR bounds learned from X (and optionally y).\n",
    "    Applied only during fit_transform; during transform it filters rows in X,\n",
    "    and if y is passed via fit(X, y) it will also align y.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols=(\"living_area\",), y_name=\"price\", y_iqr=True, room_col=\"number_rooms\", room_max=12):\n",
    "        self.cols = cols\n",
    "        self.y_name = y_name\n",
    "        self.y_iqr = y_iqr\n",
    "        self.room_col = room_col\n",
    "        self.room_max = room_max\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        self.bounds_ = {}\n",
    "\n",
    "        for c in self.cols:\n",
    "            if c in X_.columns:\n",
    "                q1 = X_[c].quantile(0.25)\n",
    "                q3 = X_[c].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                self.bounds_[c] = (q1 - 1.5 * iqr, q3 + 1.5 * iqr)\n",
    "\n",
    "        if self.y_iqr and y is not None:\n",
    "            y_series = pd.Series(y)\n",
    "            q1 = y_series.quantile(0.25)\n",
    "            q3 = y_series.quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            self.y_bounds_ = (q1 - 1.5 * iqr, q3 + 1.5 * iqr)\n",
    "        else:\n",
    "            self.y_bounds_ = None\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # During inference, do NOT drop rows. Return X unchanged.\n",
    "        # (Dropping at inference can surprise downstream consumers.)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        X_ = X.copy()\n",
    "        mask = pd.Series(True, index=X_.index)\n",
    "\n",
    "        for c, (lo, hi) in getattr(self, \"bounds_\", {}).items():\n",
    "            mask &= X_[c].between(lo, hi) | X_[c].isna()\n",
    "\n",
    "        if self.room_col in X_.columns:\n",
    "            mask &= (X_[self.room_col].fillna(0) <= self.room_max)\n",
    "\n",
    "        if getattr(self, \"y_bounds_\", None) is not None and y is not None:\n",
    "            y_series = pd.Series(y, index=X_.index)\n",
    "            lo, hi = self.y_bounds_\n",
    "            mask &= y_series.between(lo, hi)\n",
    "\n",
    "            return X_.loc[mask].copy(), y_series.loc[mask].to_numpy()\n",
    "\n",
    "        return X_.loc[mask].copy()\n",
    "\n",
    "\n",
    "# ---------- Preprocessor ----------\n",
    "def build_preprocessor(X):\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"string\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "    num_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=20))  # reduces overfitting for rare categories\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, num_cols),\n",
    "            (\"cat\", cat_pipe, cat_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- CV runner ----------\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "scoring = {\n",
    "    \"mae\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"rmse\": make_scorer(rmse, greater_is_better=False),\n",
    "    \"r2\": \"r2\"\n",
    "}\n",
    "\n",
    "\n",
    "def run_cv(df, target=\"price\", test_size=0.2, random_state=42, n_splits=5):\n",
    "    y = df[target].to_numpy()\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # final untouched test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "\n",
    "    models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForest\": RandomForestRegressor(\n",
    "            n_estimators=600,\n",
    "            min_samples_leaf=5,      # combats your observed overfitting\n",
    "            min_samples_split=10,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"XGBoost\": XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=2.0,\n",
    "            reg_alpha=0.0,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "            tree_method=\"hist\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    fitted_models = {}\n",
    "\n",
    "    for name, est in models.items():\n",
    "        pipe = Pipeline([\n",
    "            (\"trim\", IQRTrimmer(cols=(\"living_area\",), y_iqr=True)),\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"model\", est)\n",
    "        ])\n",
    "\n",
    "        cv_res = cross_validate(\n",
    "            pipe, X_train, y_train,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            return_train_score=True\n",
    "        )\n",
    "\n",
    "        # summarize (note: mae/rmse are negative because of sklearn convention)\n",
    "        rows.append({\n",
    "            \"Model\": name,\n",
    "            \"CV_MAE_mean\": -cv_res[\"test_mae\"].mean(),\n",
    "            \"CV_MAE_std\":  cv_res[\"test_mae\"].std(),\n",
    "            \"CV_RMSE_mean\": -cv_res[\"test_rmse\"].mean(),\n",
    "            \"CV_RMSE_std\":  cv_res[\"test_rmse\"].std(),\n",
    "            \"CV_R2_mean\": cv_res[\"test_r2\"].mean(),\n",
    "            \"CV_R2_std\":  cv_res[\"test_r2\"].std(),\n",
    "            \"Overfit_R2_gap(mean)\": (cv_res[\"train_r2\"].mean() - cv_res[\"test_r2\"].mean())\n",
    "        })\n",
    "\n",
    "        # fit on full train set for final test evaluation\n",
    "        pipe.fit(X_train, y_train)\n",
    "        fitted_models[name] = pipe\n",
    "\n",
    "    summary = pd.DataFrame(rows).sort_values(by=\"CV_RMSE_mean\")\n",
    "    return summary, fitted_models, (X_test, y_test)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# summary, fitted, (X_test, y_test) = run_cv(df)\n",
    "# print(summary)\n",
    "# best = min(fitted, key=lambda k: summary.set_index(\"Model\").loc[k, \"CV_RMSE_mean\"])\n",
    "# y_pred = fitted[best].predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f792f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14374, 12)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\welde\\Desktop\\immo-eliza-ml\")\n",
    "csv_path = PROJECT_ROOT / \"data\" / \"processed\" / \"cleaned_v2.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# safety: ensure target exists\n",
    "assert \"price\" in df.columns, \"Expected a 'price' column in df\"\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455f8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model  CV_MAE_mean  CV_MAE_std  CV_RMSE_mean  CV_RMSE_std  \\\n",
      "2           XGBoost     75022.55     3164.69     146751.00     14218.64   \n",
      "1      RandomForest     79590.46     2997.51     164603.72     15679.82   \n",
      "0  LinearRegression    109072.60     3607.96     199464.60     21399.84   \n",
      "\n",
      "   CV_R2_mean  CV_R2_std  Overfit_R2_gap(mean)  \n",
      "2      0.6960     0.0166                0.2329  \n",
      "1      0.6175     0.0238                0.1466  \n",
      "0      0.4389     0.0447                0.0017  \n"
     ]
    }
   ],
   "source": [
    "summary, fitted_models, (X_test, y_test) = run_cv(df, target=\"price\", n_splits=5)\n",
    "\n",
    "# Pretty display\n",
    "summary_display = summary.copy()\n",
    "for c in [\"CV_MAE_mean\", \"CV_MAE_std\", \"CV_RMSE_mean\", \"CV_RMSE_std\"]:\n",
    "    summary_display[c] = summary_display[c].round(2)\n",
    "for c in [\"CV_R2_mean\", \"CV_R2_std\", \"Overfit_R2_gap(mean)\"]:\n",
    "    summary_display[c] = summary_display[c].round(4)\n",
    "\n",
    "print(summary_display)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
