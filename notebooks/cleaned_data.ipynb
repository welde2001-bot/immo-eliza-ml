{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3696ff",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e7fa8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15232 entries, 0 to 15231\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   build_year          6226 non-null   object \n",
      " 1   facades             10088 non-null  float64\n",
      " 2   garden              15232 non-null  object \n",
      " 3   living_area         13504 non-null  object \n",
      " 4   locality_name       15012 non-null  object \n",
      " 5   number_rooms        13980 non-null  object \n",
      " 6   postal_code         15008 non-null  float64\n",
      " 7   price               14389 non-null  float64\n",
      " 8   property_id         15232 non-null  object \n",
      " 9   property_type       14236 non-null  object \n",
      " 10  property_url        15232 non-null  object \n",
      " 11  state               11116 non-null  object \n",
      " 12  swimming_pool       15232 non-null  object \n",
      " 13  terrace             13832 non-null  object \n",
      " 14  province            15008 non-null  object \n",
      " 15  property_type_name  14232 non-null  object \n",
      " 16  state_mapped        11112 non-null  object \n",
      "dtypes: float64(3), object(14)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b792b879-01bb-4931-b2aa-a1373ac7bd93",
       "rows": [
        [
         "build_year",
         "9006"
        ],
        [
         "facades",
         "5144"
        ],
        [
         "garden",
         "0"
        ],
        [
         "living_area",
         "1728"
        ],
        [
         "locality_name",
         "220"
        ],
        [
         "number_rooms",
         "1252"
        ],
        [
         "postal_code",
         "224"
        ],
        [
         "price",
         "843"
        ],
        [
         "property_id",
         "0"
        ],
        [
         "property_type",
         "996"
        ],
        [
         "property_url",
         "0"
        ],
        [
         "state",
         "4116"
        ],
        [
         "swimming_pool",
         "0"
        ],
        [
         "terrace",
         "1400"
        ],
        [
         "province",
         "224"
        ],
        [
         "property_type_name",
         "1000"
        ],
        [
         "state_mapped",
         "4120"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 17
       }
      },
      "text/plain": [
       "build_year            9006\n",
       "facades               5144\n",
       "garden                   0\n",
       "living_area           1728\n",
       "locality_name          220\n",
       "number_rooms          1252\n",
       "postal_code            224\n",
       "price                  843\n",
       "property_id              0\n",
       "property_type          996\n",
       "property_url             0\n",
       "state                 4116\n",
       "swimming_pool            0\n",
       "terrace               1400\n",
       "province               224\n",
       "property_type_name    1000\n",
       "state_mapped          4120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\welde\\Desktop\\immo-eliza-ml\")  # Change Python's working directory so that all relative paths are resolved from your project root\n",
    "\n",
    "\n",
    "# load the data set\n",
    "\n",
    "df = pd.read_csv(\"data/raw/raw.csv\")\n",
    "df.head()      # \n",
    "df.shape       # Check dataset shape\n",
    "df.info()       # Inspect column data types\n",
    "df.describe()    #Summary statistics\n",
    "df.isna().sum()   #missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f7473",
   "metadata": {},
   "source": [
    "## DATA CLEANING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f226214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def enhanced_cleaning(\n",
    "        path=\"data/raw/raw.csv\",\n",
    "        save_path=\"data/processed/cleaned_v2.csv\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    FINAL unified cleaning pipeline for ImmoEliza.\n",
    "    - Merges basic cleaning + enhanced cleaning\n",
    "    - Handles numeric sanity, boolean normalization\n",
    "    - Reduces locality noise (top 200)\n",
    "    - Prepares data for feature engineering\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Load raw-cleaned data\n",
    "    df = pd.read_csv(path, dtype={\"postal_code\": \"string\"}).copy()\n",
    "\n",
    "    # 2. Drop useless columns\n",
    "    drop_cols = [\n",
    "        \"property_id\",\n",
    "        \"property_url\",\n",
    "        \"property_type_name\",\n",
    "        \"state_mapped\"\n",
    "    ]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    # 3. Normalize boolean-like columns\n",
    "    bool_cols = [\"garden\", \"terrace\", \"swimming_pool\"]\n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = (\n",
    "                df[col].astype(str).str.lower().str.strip()\n",
    "                .replace({\n",
    "                    \"1\": \"yes\", \"true\": \"yes\", \"yes\": \"yes\",\n",
    "                    \"0\": \"no\", \"false\": \"no\", \"no\": \"no\"\n",
    "                })\n",
    "            )\n",
    "\n",
    "    # 4. Convert numeric-like columns (comma → dot)\n",
    "    numeric_cols = [\"build_year\", \"number_rooms\", \"facades\", \"living_area\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.replace(\",\", \".\", regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Ensure price numeric\n",
    "    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "    # Postal code stays categorical\n",
    "    df[\"postal_code\"] = df[\"postal_code\"].astype(\"string\")\n",
    "\n",
    "    # 5. Numeric sanity constraints\n",
    "    df.loc[df[\"build_year\"] < 1800, \"build_year\"] = np.nan\n",
    "    df.loc[df[\"build_year\"] > 2025, \"build_year\"] = np.nan\n",
    "\n",
    "    df.loc[df[\"number_rooms\"] <= 0, \"number_rooms\"] = np.nan\n",
    "    df.loc[df[\"number_rooms\"] > 12, \"number_rooms\"] = np.nan\n",
    "\n",
    "    df.loc[df[\"living_area\"] < 10, \"living_area\"] = np.nan\n",
    "    df.loc[df[\"living_area\"] > 500, \"living_area\"] = np.nan\n",
    "\n",
    "    df = df[df[\"price\"] >= 10000]\n",
    "    df.loc[df[\"price\"] > 7_500_000, \"price\"] = np.nan\n",
    "    df = df[df[\"price\"].notna()]\n",
    "\n",
    "    df[\"province\"] = df[\"province\"].astype(str).str.strip().replace(\"nan\", np.nan)\n",
    "\n",
    "    # 6. Reduce locality high-cardinality noise (top 200)\n",
    "    if \"locality_name\" in df.columns:\n",
    "        top_localities = df[\"locality_name\"].value_counts().head(200).index\n",
    "        df[\"locality_name\"] = df[\"locality_name\"].where(\n",
    "            df[\"locality_name\"].isin(top_localities),\n",
    "            \"Other\"\n",
    "        )\n",
    "\n",
    "    # 7. Save\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"Enhanced Cleaned dataset saved to: {save_path}\")\n",
    "    print(\"Final shape:\", df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a29adfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Cleaned dataset saved to: data/processed/cleaned_v2.csv\n",
      "Final shape: (14374, 13)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "build_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "facades",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "garden",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "living_area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "locality_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_rooms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postal_code",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "property_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "swimming_pool",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "terrace",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "province",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0d5c4303-ba6d-4cd5-82f3-cb19210237a2",
       "rows": [
        [
         "0",
         "1996.0",
         "2.0",
         "yes",
         "270.0",
         "Other",
         "4.0",
         "1853.0",
         "580000.0",
         "Residence",
         "Excellent",
         "no",
         "yes",
         "Flemish Brabant"
        ],
        [
         "1",
         "1991.0",
         "4.0",
         "yes",
         "218.0",
         "Other",
         "5.0",
         "1341.0",
         "695000.0",
         "Residence",
         "Excellent",
         "yes",
         "yes",
         "Walloon Brabant"
        ],
        [
         "2",
         "1970.0",
         "4.0",
         "no",
         "135.0",
         "Other",
         "3.0",
         "1300.0",
         "249000.0",
         "Apartment",
         "To be renovated",
         "no",
         "yes",
         "Walloon Brabant"
        ],
        [
         "3",
         "1959.0",
         "3.0",
         "yes",
         "176.0",
         "Other",
         "3.0",
         "1853.0",
         "499000.0",
         "Residence",
         "Normal",
         "no",
         "yes",
         "Flemish Brabant"
        ],
        [
         "4",
         "2007.0",
         "4.0",
         "yes",
         "200.0",
         "Other",
         "4.0",
         "1341.0",
         "650000.0",
         "Residence",
         "Excellent",
         "no",
         "yes",
         "Walloon Brabant"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build_year</th>\n",
       "      <th>facades</th>\n",
       "      <th>garden</th>\n",
       "      <th>living_area</th>\n",
       "      <th>locality_name</th>\n",
       "      <th>number_rooms</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>state</th>\n",
       "      <th>swimming_pool</th>\n",
       "      <th>terrace</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>270.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Flemish Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>218.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>695000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>To be renovated</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>176.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>499000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Flemish Brabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   build_year  facades garden  living_area locality_name  number_rooms  \\\n",
       "0      1996.0      2.0    yes        270.0         Other           4.0   \n",
       "1      1991.0      4.0    yes        218.0         Other           5.0   \n",
       "2      1970.0      4.0     no        135.0         Other           3.0   \n",
       "3      1959.0      3.0    yes        176.0         Other           3.0   \n",
       "4      2007.0      4.0    yes        200.0         Other           4.0   \n",
       "\n",
       "  postal_code     price property_type            state swimming_pool terrace  \\\n",
       "0      1853.0  580000.0     Residence        Excellent            no     yes   \n",
       "1      1341.0  695000.0     Residence        Excellent           yes     yes   \n",
       "2      1300.0  249000.0     Apartment  To be renovated            no     yes   \n",
       "3      1853.0  499000.0     Residence           Normal            no     yes   \n",
       "4      1341.0  650000.0     Residence        Excellent            no     yes   \n",
       "\n",
       "          province  \n",
       "0  Flemish Brabant  \n",
       "1  Walloon Brabant  \n",
       "2  Walloon Brabant  \n",
       "3  Flemish Brabant  \n",
       "4  Walloon Brabant  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "cleaned_df = enhanced_cleaning(\n",
    "    path=\"data/raw/raw.csv\",\n",
    "    save_path=\"data/processed/cleaned_v2.csv\"\n",
    ")\n",
    "\n",
    "cleaned_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27445a2f",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "32db2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def feature_engineering(\n",
    "        path=\"data/processed/cleaned_v2.csv\",\n",
    "        save_path=\"data/processed/feature_engineered.csv\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    FINAL Feature Engineering for ImmoEliza.\n",
    "    Must be run AFTER the unified enhanced cleaning step.\n",
    "    \n",
    "    Adds:\n",
    "    - postal_prefix\n",
    "    - house_age, build_decade\n",
    "    - is_new_build / is_recent / is_old\n",
    "    - boolean flags (garden_flag, etc.)\n",
    "    - region (Flanders/Wallonia/Brussels)\n",
    "    - normalized locality_name\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path, dtype={\"postal_code\": \"string\"}).copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1. Postal code remains categorical\n",
    "    # ------------------------------------------------------------\n",
    "    df[\"postal_code\"] = df[\"postal_code\"].fillna(\"unknown\").astype(\"string\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. Build-year engineering\n",
    "    # ------------------------------------------------------------\n",
    "    if \"build_year\" in df.columns:\n",
    "        current_year = 2024\n",
    "\n",
    "        df[\"house_age\"] = current_year - df[\"build_year\"]\n",
    "        df.loc[df[\"house_age\"] < 0, \"house_age\"] = np.nan\n",
    "\n",
    "        df[\"is_new_build\"] = (df[\"house_age\"] <= 5).astype(\"Int64\")\n",
    "        df[\"is_recent\"]     = (df[\"house_age\"] <= 20).astype(\"Int64\")\n",
    "        df[\"is_old\"]        = (df[\"house_age\"] >= 50).astype(\"Int64\")\n",
    "\n",
    "        df[\"build_decade\"] = (df[\"build_year\"] // 10 * 10).astype(\"Int64\")\n",
    "    else:\n",
    "        df[\"house_age\"] = np.nan\n",
    "        df[\"is_new_build\"] = np.nan\n",
    "        df[\"is_recent\"] = np.nan\n",
    "        df[\"is_old\"] = np.nan\n",
    "        df[\"build_decade\"] = np.nan\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. Region mapping (province → region)\n",
    "    # ------------------------------------------------------------\n",
    "    region_map = {\n",
    "        \"Antwerp\": \"Flanders\",\n",
    "        \"East Flanders\": \"Flanders\",\n",
    "        \"West Flanders\": \"Flanders\",\n",
    "        \"Limburg\": \"Flanders\",\n",
    "        \"Flemish Brabant\": \"Flanders\",\n",
    "\n",
    "        \"Walloon Brabant\": \"Wallonia\",\n",
    "        \"Hainaut\": \"Wallonia\",\n",
    "        \"Liège\": \"Wallonia\",\n",
    "        \"Luxembourg\": \"Wallonia\",\n",
    "        \"Namur\": \"Wallonia\",\n",
    "\n",
    "        \"Brussels\": \"Brussels\"\n",
    "    }\n",
    "\n",
    "    df[\"region\"] = df[\"province\"].map(region_map).fillna(\"unknown\").astype(\"string\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. Boolean flags\n",
    "    # ------------------------------------------------------------\n",
    "    bool_map = {\"yes\": 1, \"no\": 0}\n",
    "\n",
    "    for col in [\"garden\", \"terrace\", \"swimming_pool\"]:\n",
    "        if col in df.columns:\n",
    "            df[col + \"_flag\"] = df[col].map(bool_map).astype(\"Int64\")\n",
    "        else:\n",
    "            df[col + \"_flag\"] = np.nan\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5. Locality normalization\n",
    "    # ------------------------------------------------------------\n",
    "    df[\"locality_name\"] = df[\"locality_name\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6. Postal prefix (categorical location smoothing)\n",
    "    # ------------------------------------------------------------\n",
    "    df[\"postal_prefix\"] = df[\"postal_code\"].str[:2].astype(\"string\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 7. Save engineered dataset\n",
    "    # ------------------------------------------------------------\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"Feature-engineered dataset saved to: {save_path}\")\n",
    "    print(\"Final shape:\", df.shape)\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6829503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered dataset saved to: data/processed/feature_engineered.csv\n",
      "Final shape: (14374, 23)\n",
      "\n",
      "Columns: ['build_year', 'facades', 'garden', 'living_area', 'locality_name', 'number_rooms', 'postal_code', 'price', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'region', 'garden_flag', 'terrace_flag', 'swimming_pool_flag', 'postal_prefix']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "build_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "facades",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "garden",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "living_area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "locality_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_rooms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postal_code",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "property_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "swimming_pool",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "terrace",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "house_age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_new_build",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "is_recent",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "is_old",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "build_decade",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "region",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "garden_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "terrace_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "swimming_pool_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "postal_prefix",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "37040cc7-fd9b-4050-9637-fa7b9b06f410",
       "rows": [
        [
         "0",
         "1996.0",
         "2.0",
         "yes",
         "270.0",
         "other",
         "4.0",
         "1853.0",
         "580000.0",
         "Residence",
         "Excellent",
         "no",
         "yes",
         "Flemish Brabant",
         "28.0",
         "0",
         "0",
         "0",
         "1990",
         "Flanders",
         "1",
         "1",
         "0",
         "18"
        ],
        [
         "1",
         "1991.0",
         "4.0",
         "yes",
         "218.0",
         "other",
         "5.0",
         "1341.0",
         "695000.0",
         "Residence",
         "Excellent",
         "yes",
         "yes",
         "Walloon Brabant",
         "33.0",
         "0",
         "0",
         "0",
         "1990",
         "Wallonia",
         "1",
         "1",
         "1",
         "13"
        ],
        [
         "2",
         "1970.0",
         "4.0",
         "no",
         "135.0",
         "other",
         "3.0",
         "1300.0",
         "249000.0",
         "Apartment",
         "To be renovated",
         "no",
         "yes",
         "Walloon Brabant",
         "54.0",
         "0",
         "0",
         "1",
         "1970",
         "Wallonia",
         "0",
         "1",
         "0",
         "13"
        ],
        [
         "3",
         "1959.0",
         "3.0",
         "yes",
         "176.0",
         "other",
         "3.0",
         "1853.0",
         "499000.0",
         "Residence",
         "Normal",
         "no",
         "yes",
         "Flemish Brabant",
         "65.0",
         "0",
         "0",
         "1",
         "1950",
         "Flanders",
         "1",
         "1",
         "0",
         "18"
        ],
        [
         "4",
         "2007.0",
         "4.0",
         "yes",
         "200.0",
         "other",
         "4.0",
         "1341.0",
         "650000.0",
         "Residence",
         "Excellent",
         "no",
         "yes",
         "Walloon Brabant",
         "17.0",
         "0",
         "1",
         "0",
         "2000",
         "Wallonia",
         "1",
         "1",
         "0",
         "13"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build_year</th>\n",
       "      <th>facades</th>\n",
       "      <th>garden</th>\n",
       "      <th>living_area</th>\n",
       "      <th>locality_name</th>\n",
       "      <th>number_rooms</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>house_age</th>\n",
       "      <th>is_new_build</th>\n",
       "      <th>is_recent</th>\n",
       "      <th>is_old</th>\n",
       "      <th>build_decade</th>\n",
       "      <th>region</th>\n",
       "      <th>garden_flag</th>\n",
       "      <th>terrace_flag</th>\n",
       "      <th>swimming_pool_flag</th>\n",
       "      <th>postal_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>270.0</td>\n",
       "      <td>other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>218.0</td>\n",
       "      <td>other</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>695000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>135.0</td>\n",
       "      <td>other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>To be renovated</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>176.0</td>\n",
       "      <td>other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>499000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Normal</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>200.0</td>\n",
       "      <td>other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   build_year  facades garden  living_area locality_name  number_rooms  \\\n",
       "0      1996.0      2.0    yes        270.0         other           4.0   \n",
       "1      1991.0      4.0    yes        218.0         other           5.0   \n",
       "2      1970.0      4.0     no        135.0         other           3.0   \n",
       "3      1959.0      3.0    yes        176.0         other           3.0   \n",
       "4      2007.0      4.0    yes        200.0         other           4.0   \n",
       "\n",
       "  postal_code     price property_type            state  ... house_age  \\\n",
       "0      1853.0  580000.0     Residence        Excellent  ...      28.0   \n",
       "1      1341.0  695000.0     Residence        Excellent  ...      33.0   \n",
       "2      1300.0  249000.0     Apartment  To be renovated  ...      54.0   \n",
       "3      1853.0  499000.0     Residence           Normal  ...      65.0   \n",
       "4      1341.0  650000.0     Residence        Excellent  ...      17.0   \n",
       "\n",
       "  is_new_build is_recent  is_old  build_decade    region  garden_flag  \\\n",
       "0            0         0       0          1990  Flanders            1   \n",
       "1            0         0       0          1990  Wallonia            1   \n",
       "2            0         0       1          1970  Wallonia            0   \n",
       "3            0         0       1          1950  Flanders            1   \n",
       "4            0         1       0          2000  Wallonia            1   \n",
       "\n",
       "   terrace_flag swimming_pool_flag  postal_prefix  \n",
       "0             1                  0             18  \n",
       "1             1                  1             13  \n",
       "2             1                  0             13  \n",
       "3             1                  0             18  \n",
       "4             1                  0             13  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN IT\n",
    "\n",
    "fe_df = feature_engineering()\n",
    "fe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90dedd",
   "metadata": {},
   "source": [
    "## PREPROCESS DATA (Pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cbaed627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. TRAIN / TEST SPLIT (80 / 20)\n",
    "# ------------------------------------------------------------\n",
    "def split_data(df, target=\"price\"):\n",
    "    \"\"\"\n",
    "    Split dataset into train and test sets (80/20).\n",
    "    \"\"\"\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. OUTLIER REMOVAL FROM TRAINING SET ONLY\n",
    "# ------------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Remove outliers ONLY from the training dataset\n",
    "    (NO validation/test leakage).\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    cols_to_filter = [col for col in [\"price\", \"living_area\"] if col in df_train.columns]\n",
    "\n",
    "    def iqr_filter(df, col):\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    for col in cols_to_filter:\n",
    "        df_train = iqr_filter(df_train, col)\n",
    "\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Training after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. BUILD PREPROCESSOR (numeric + categorical)\n",
    "# ------------------------------------------------------------\n",
    "def build_preprocessor(X_train):\n",
    "    \"\"\"\n",
    "    Build preprocessing transformer for numeric and categorical features.\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_cols = X_train.select_dtypes(\n",
    "        include=[\"float64\", \"int64\", \"Int64\"]\n",
    "    ).columns.tolist()\n",
    "\n",
    "    categorical_cols = X_train.select_dtypes(\n",
    "        include=[\"object\", \"string\"]\n",
    "    ).columns.tolist()\n",
    "\n",
    "    # Ensure postal_code stays categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"\\nNumeric columns:\", numeric_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. MAIN PIPELINE FUNCTION (AFTER FEATURE ENGINEERING)\n",
    "# ------------------------------------------------------------\n",
    "def run_preprocessing_pipeline(path=\"data/processed/cleaned_v2.csv\"):\n",
    "    \"\"\"\n",
    "    Load engineered dataset, enforce postal_code dtype,\n",
    "    split 80/20, remove outliers, and build preprocessing pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path, dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "    # 80/20 split\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # Remove outliers ONLY from train\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Build final preprocessor\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    return X_train_clean, X_test, y_train_clean, y_test, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ac2d141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 15)\n",
      "Test: (2875, 15)\n",
      "Training after outlier removal: (9169, 15)\n",
      "\n",
      "Numeric columns: ['build_year', 'facades', 'living_area', 'number_rooms', 'postal_code_num', 'postal_prefix']\n",
      "Categorical columns: ['garden', 'locality_name', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# RUN THE PIPELINE\n",
    "# ------------------------------------------------------------\n",
    "X_train_clean, X_test, y_train_clean, y_test, preprocessor = run_preprocessing_pipeline(\n",
    "    \"data/processed/cleaned_v2.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff57939",
   "metadata": {},
   "source": [
    "## Tuned Linear Models: Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80df6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Evaluate a single split\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_split(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Train tuned linear models (Ridge, Lasso, ElasticNet)\n",
    "# -------------------------------------------------------------\n",
    "def train_tuned_linear_models(X_train, y_train, preprocessor):\n",
    "\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(),\n",
    "        \"Lasso\": Lasso(max_iter=10000),\n",
    "        \"ElasticNet\": ElasticNet(max_iter=10000)\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Ridge\": {\"model__alpha\": [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "        \"Lasso\": {\"model__alpha\": [0.001, 0.01, 0.1, 1, 10]},\n",
    "        \"ElasticNet\": {\n",
    "            \"model__alpha\": [0.001, 0.01, 0.1, 1],\n",
    "            \"model__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_distributions=param_grids[name],\n",
    "            n_iter=10,\n",
    "            scoring=\"neg_mean_absolute_error\",\n",
    "            cv=3,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Best params for {name}: {search.best_params_}\")\n",
    "        best_models[name] = search.best_estimator_\n",
    "\n",
    "    return best_models\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Full workflow: Train/Test only (NO validation)\n",
    "# -------------------------------------------------------------\n",
    "def run_tuned_linear_models(\n",
    "    X_train_clean, X_test,\n",
    "    y_train_clean, y_test,\n",
    "    preprocessor\n",
    "):\n",
    "\n",
    "    best_models = train_tuned_linear_models(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for name, model in best_models.items():\n",
    "        print(f\"\\n===== {name} Results =====\")\n",
    "\n",
    "        # Train performance\n",
    "        all_results.append(evaluate_split(\n",
    "            model, X_train_clean, y_train_clean, f\"{name} - Train\"\n",
    "        ))\n",
    "\n",
    "        # Test performance\n",
    "        all_results.append(evaluate_split(\n",
    "            model, X_test, y_test, f\"{name} - Test\"\n",
    "        ))\n",
    "\n",
    "        # Save model\n",
    "        model_path = f\"models/{name.lower()}_tuned.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"{name} model saved to {model_path}\")\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1deded6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Ridge: {'model__alpha': 1}\n",
      "\n",
      "Tuning Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Lasso: {'model__alpha': 10}\n",
      "\n",
      "Tuning ElasticNet...\n",
      "Best params for ElasticNet: {'model__l1_ratio': 0.7, 'model__alpha': 0.001}\n",
      "\n",
      "===== Ridge Results =====\n",
      "\n",
      "--- Ridge - Train Evaluation ---\n",
      "MAE:  49,130.67\n",
      "RMSE: 66,751.69\n",
      "R²:   0.7188\n",
      "\n",
      "--- Ridge - Test Evaluation ---\n",
      "MAE:  89,479.28\n",
      "RMSE: 189,515.28\n",
      "R²:   0.4365\n",
      "Ridge model saved to models/ridge_tuned.pkl\n",
      "\n",
      "===== Lasso Results =====\n",
      "\n",
      "--- Lasso - Train Evaluation ---\n",
      "MAE:  49,788.06\n",
      "RMSE: 67,395.84\n",
      "R²:   0.7134\n",
      "\n",
      "--- Lasso - Test Evaluation ---\n",
      "MAE:  89,432.08\n",
      "RMSE: 189,757.50\n",
      "R²:   0.4351\n",
      "Lasso model saved to models/lasso_tuned.pkl\n",
      "\n",
      "===== ElasticNet Results =====\n",
      "\n",
      "--- ElasticNet - Train Evaluation ---\n",
      "MAE:  49,992.56\n",
      "RMSE: 67,832.86\n",
      "R²:   0.7096\n",
      "\n",
      "--- ElasticNet - Test Evaluation ---\n",
      "MAE:  89,489.81\n",
      "RMSE: 190,006.94\n",
      "R²:   0.4336\n",
      "ElasticNet model saved to models/elasticnet_tuned.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e+13, tolerance: 1.453e+10\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3bf4b564-aa4f-43f3-b675-2999630761f7",
       "rows": [
        [
         "0",
         "Ridge - Train",
         "49130.66754410802",
         "66751.68920951168",
         "0.7188161354137272"
        ],
        [
         "1",
         "Ridge - Test",
         "89479.28012514133",
         "189515.28133622705",
         "0.43649568752303514"
        ],
        [
         "2",
         "Lasso - Train",
         "49788.0571044138",
         "67395.84051666124",
         "0.713363123494559"
        ],
        [
         "3",
         "Lasso - Test",
         "89432.07833125605",
         "189757.5029327432",
         "0.43505432469669714"
        ],
        [
         "4",
         "ElasticNet - Train",
         "49992.56174402031",
         "67832.86107186292",
         "0.7096337436668344"
        ],
        [
         "5",
         "ElasticNet - Test",
         "89489.8059200306",
         "190006.93715894216",
         "0.43356811833335396"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge - Train</td>\n",
       "      <td>49130.667544</td>\n",
       "      <td>66751.689210</td>\n",
       "      <td>0.718816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge - Test</td>\n",
       "      <td>89479.280125</td>\n",
       "      <td>189515.281336</td>\n",
       "      <td>0.436496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso - Train</td>\n",
       "      <td>49788.057104</td>\n",
       "      <td>67395.840517</td>\n",
       "      <td>0.713363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso - Test</td>\n",
       "      <td>89432.078331</td>\n",
       "      <td>189757.502933</td>\n",
       "      <td>0.435054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet - Train</td>\n",
       "      <td>49992.561744</td>\n",
       "      <td>67832.861072</td>\n",
       "      <td>0.709634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet - Test</td>\n",
       "      <td>89489.805920</td>\n",
       "      <td>190006.937159</td>\n",
       "      <td>0.433568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Split           MAE           RMSE        R2\n",
       "0       Ridge - Train  49130.667544   66751.689210  0.718816\n",
       "1        Ridge - Test  89479.280125  189515.281336  0.436496\n",
       "2       Lasso - Train  49788.057104   67395.840517  0.713363\n",
       "3        Lasso - Test  89432.078331  189757.502933  0.435054\n",
       "4  ElasticNet - Train  49992.561744   67832.861072  0.709634\n",
       "5   ElasticNet - Test  89489.805920  190006.937159  0.433568"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_linear_results = run_tuned_linear_models(\n",
    "    X_train_clean, X_test,\n",
    "    y_train_clean, y_test,\n",
    "    preprocessor\n",
    ")\n",
    "\n",
    "tuned_linear_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5daad",
   "metadata": {},
   "source": [
    "## Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24be7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Train Linear Regression (Pipeline = Preprocessor + LR)\n",
    "# ============================================================\n",
    "def train_linear_regression(X_train, y_train, preprocessor):\n",
    "    \"\"\"\n",
    "    Build and train a full pipeline:\n",
    "    - Preprocessor: ColumnTransformer\n",
    "    - Linear Regression model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nLinear Regression model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Evaluate one split (Train or Test)\n",
    "# ============================================================\n",
    "def evaluate_single_split(model, X, y, split_name=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given split.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5   # manual RMSE\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Evaluate Train + Test (NO validation)\n",
    "# ============================================================\n",
    "def evaluate_all_splits(model,\n",
    "                        X_train, y_train,\n",
    "                        X_test, y_test,\n",
    "                        model_name=\"Linear Regression\"):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Train\n",
    "    tr_mae, tr_rmse, tr_r2 = evaluate_single_split(\n",
    "        model, X_train, y_train, \"Train\"\n",
    "    )\n",
    "\n",
    "    # Test\n",
    "    te_mae, te_rmse, te_r2 = evaluate_single_split(\n",
    "        model, X_test, y_test, \"Test\"\n",
    "    )\n",
    "\n",
    "    # Summary DataFrame\n",
    "    df_results = pd.DataFrame([\n",
    "        {\"Model\": model_name, \"Split\": \"Train\", \"MAE\": tr_mae, \"RMSE\": tr_rmse, \"R2\": tr_r2},\n",
    "        {\"Model\": model_name, \"Split\": \"Test\", \"MAE\": te_mae, \"RMSE\": te_rmse, \"R2\": te_r2},\n",
    "    ])\n",
    "\n",
    "    print(\"\\n--- Summary Performance Table ---\")\n",
    "    print(df_results)\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Save model to disk\n",
    "# ============================================================\n",
    "def save_linear_regression(model, path=\"models/linear_regression.pkl\"):\n",
    "    \"\"\"\n",
    "    Save the full model pipeline (Preprocessor + Linear Regression).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    joblib.dump(model, path)\n",
    "\n",
    "    print(f\"\\nModel pipeline saved to: {path}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Full Linear Regression Workflow (Train/Test Only)\n",
    "# ============================================================\n",
    "def run_linear_regression(X_train_clean, X_test,\n",
    "                          y_train_clean, y_test,\n",
    "                          preprocessor):\n",
    "    \"\"\"\n",
    "    End-to-end workflow:\n",
    "    - Train LR model\n",
    "    - Evaluate on train/test (no validation)\n",
    "    - Save model\n",
    "    - Return model + performance table\n",
    "    \"\"\"\n",
    "\n",
    "    # Train model\n",
    "    model = train_linear_regression(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    scores = evaluate_all_splits(\n",
    "        model,\n",
    "        X_train_clean, y_train_clean,\n",
    "        X_test, y_test,\n",
    "        model_name=\"Linear Regression\"\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    save_linear_regression(model)\n",
    "\n",
    "    return model, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0129cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  48,289.47\n",
      "RMSE: 66,177.99\n",
      "R²:   0.7236\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  90,186.10\n",
      "RMSE: 189,667.52\n",
      "R²:   0.4356\n",
      "\n",
      "--- Summary Performance Table ---\n",
      "               Model  Split           MAE           RMSE        R2\n",
      "0  Linear Regression  Train  48289.470068   66177.990337  0.723629\n",
      "1  Linear Regression   Test  90186.101096  189667.515591  0.435590\n",
      "\n",
      "Model pipeline saved to: models/linear_regression.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ba26c5f3-f431-493b-9834-985fd7902c8b",
       "rows": [
        [
         "0",
         "Linear Regression",
         "Train",
         "48289.470067546754",
         "66177.99033731548",
         "0.7236286474504919"
        ],
        [
         "1",
         "Linear Regression",
         "Test",
         "90186.1010964675",
         "189667.51559096362",
         "0.4355900179317378"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Train</td>\n",
       "      <td>48289.470068</td>\n",
       "      <td>66177.990337</td>\n",
       "      <td>0.723629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Test</td>\n",
       "      <td>90186.101096</td>\n",
       "      <td>189667.515591</td>\n",
       "      <td>0.435590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Split           MAE           RMSE        R2\n",
       "0  Linear Regression  Train  48289.470068   66177.990337  0.723629\n",
       "1  Linear Regression   Test  90186.101096  189667.515591  0.435590"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model, lr_results = run_linear_regression(\n",
    "    X_train_clean, X_test,\n",
    "    y_train_clean, y_test,\n",
    "    preprocessor\n",
    ")\n",
    "\n",
    "lr_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9b2d3",
   "metadata": {},
   "source": [
    "## leakage testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6292c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "def drift_check(X_train_clean, X_test, y_train_clean, y_test):\n",
    "    print(\"\\n==============================\")\n",
    "    print(\" DRIFT ANALYSIS STARTING\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Reconstruct full train/test DataFrames\n",
    "    # --------------------------------------------------------\n",
    "    train = X_train_clean.copy()\n",
    "    test = X_test.copy()\n",
    "\n",
    "    train[\"price\"] = y_train_clean.values\n",
    "    test[\"price\"] = y_test.values\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Identify columns\n",
    "    # --------------------------------------------------------\n",
    "    numeric_cols = train.select_dtypes(include=[\"float64\",\"int64\",\"Int64\"]).columns.tolist()\n",
    "    categorical_cols = train.select_dtypes(include=[\"object\",\"string\"]).columns.tolist()\n",
    "\n",
    "    # Ensure price treated as numeric\n",
    "    if \"price\" in categorical_cols:\n",
    "        categorical_cols.remove(\"price\")\n",
    "        numeric_cols.append(\"price\")\n",
    "\n",
    "    print(\"Numeric columns:\", numeric_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. Category Coverage Checks\n",
    "    # --------------------------------------------------------\n",
    "    def category_coverage(feature):\n",
    "        train_set = set(train[feature].dropna())\n",
    "        test_set = set(test[feature].dropna())\n",
    "\n",
    "        missing_in_train = test_set - train_set\n",
    "        missing_in_test = train_set - test_set\n",
    "\n",
    "        print(f\"\\n=== CATEGORY COVERAGE: {feature} ===\")\n",
    "        print(f\"Unique in train: {len(train_set)}\")\n",
    "        print(f\"Unique in test:  {len(test_set)}\")\n",
    "        print(f\"Present in TEST but NOT in train (unseen categories): {len(missing_in_train)}\")\n",
    "        if len(missing_in_train) > 0:\n",
    "            print(\"Examples:\", list(missing_in_train)[:15])\n",
    "        print(f\"Present in TRAIN but NOT in test: {len(missing_in_test)}\")\n",
    "\n",
    "    print(\"\\n========== CHECKING CATEGORY COVERAGE ==========\\n\")\n",
    "    for col in categorical_cols:\n",
    "        category_coverage(col)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. KS Tests for Numerical Drift\n",
    "    # --------------------------------------------------------\n",
    "    def ks_test(feature):\n",
    "        a = train[feature].dropna()\n",
    "        b = test[feature].dropna()\n",
    "\n",
    "        stat, p = ks_2samp(a, b)\n",
    "\n",
    "        print(f\"\\n=== KS TEST: {feature} ===\")\n",
    "        print(f\"KS statistic: {stat:.4f}\")\n",
    "        print(f\"P-value     : {p:.6f}\")\n",
    "\n",
    "        if p < 0.05:\n",
    "            print(\" -> SIGNIFICANT DRIFT DETECTED\")\n",
    "        else:\n",
    "            print(\" -> No significant drift\")\n",
    "\n",
    "    print(\"\\n========== KS-TEST FOR NUMERICAL FEATURES ==========\\n\")\n",
    "\n",
    "    # You normally do NOT test price for KS, but here we include it to see target drift\n",
    "    for col in numeric_cols:\n",
    "        ks_test(col)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. Target Drift Summary\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\n========== TARGET DRIFT (PRICE DISTRIBUTION) ==========\\n\")\n",
    "    print(\"Train price stats:\")\n",
    "    print(train[\"price\"].describe())\n",
    "\n",
    "    print(\"\\nTest price stats:\")\n",
    "    print(test[\"price\"].describe())\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6. Interaction Drift: Locality-level mean price\n",
    "    # --------------------------------------------------------\n",
    "    if \"locality_name\" in train.columns:\n",
    "        print(\"\\n========== LOCALITY-LEVEL PRICE DRIFT ==========\\n\")\n",
    "\n",
    "        train_loc_means = train.groupby(\"locality_name\")[\"price\"].mean()\n",
    "        test_loc_means = test.groupby(\"locality_name\")[\"price\"].mean()\n",
    "\n",
    "        print(\"\\nTrain locality price mean distribution:\")\n",
    "        print(train_loc_means.describe())\n",
    "\n",
    "        print(\"\\nTest locality price mean distribution:\")\n",
    "        print(test_loc_means.describe())\n",
    "\n",
    "        # common localities only\n",
    "        common = list(set(train_loc_means.index) & set(test_loc_means.index))\n",
    "\n",
    "        paired_train = train_loc_means.loc[common]\n",
    "        paired_test = test_loc_means.loc[common]\n",
    "\n",
    "        stat, p = ks_2samp(paired_train, paired_test)\n",
    "\n",
    "        print(\"\\nLocality-level KS test (common localities):\")\n",
    "        print(f\"KS statistic: {stat:.4f}\")\n",
    "        print(f\"P-value     : {p:.6f}\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\" DRIFT ANALYSIS COMPLETE\")\n",
    "    print(\"==============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "324dbd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 23)\n",
      "Test: (2875, 23)\n",
      "Train after outlier removal: (9169, 23)\n",
      "\n",
      "==============================\n",
      " DRIFT ANALYSIS STARTING\n",
      "==============================\n",
      "\n",
      "Numeric columns: ['build_year', 'facades', 'living_area', 'number_rooms', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'garden_flag', 'terrace_flag', 'swimming_pool_flag', 'postal_prefix', 'postal_code_num', 'price']\n",
      "Categorical columns: ['garden', 'locality_name', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n",
      "\n",
      "========== CHECKING CATEGORY COVERAGE ==========\n",
      "\n",
      "\n",
      "=== CATEGORY COVERAGE: garden ===\n",
      "Unique in train: 2\n",
      "Unique in test:  2\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: locality_name ===\n",
      "Unique in train: 51\n",
      "Unique in test:  51\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: postal_code ===\n",
      "Unique in train: 779\n",
      "Unique in test:  573\n",
      "Present in TEST but NOT in train (unseen categories): 41\n",
      "Examples: ['9112.0', '6010.0', '8820.0', '7618.0', '6741.0', '3061.0', '3631.0', '2243.0', '7180.0', '8211.0', '6856.0', '6812.0', '7740.0', '3798.0', '5501.0']\n",
      "Present in TRAIN but NOT in test: 247\n",
      "\n",
      "=== CATEGORY COVERAGE: property_type ===\n",
      "Unique in train: 15\n",
      "Unique in test:  18\n",
      "Present in TEST but NOT in train (unseen categories): 4\n",
      "Examples: ['Commercial', 'Land', 'Development', 'Mansion']\n",
      "Present in TRAIN but NOT in test: 1\n",
      "\n",
      "=== CATEGORY COVERAGE: state ===\n",
      "Unique in train: 9\n",
      "Unique in test:  9\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: swimming_pool ===\n",
      "Unique in train: 2\n",
      "Unique in test:  2\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: terrace ===\n",
      "Unique in train: 2\n",
      "Unique in test:  2\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: province ===\n",
      "Unique in train: 11\n",
      "Unique in test:  11\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "=== CATEGORY COVERAGE: region ===\n",
      "Unique in train: 3\n",
      "Unique in test:  3\n",
      "Present in TEST but NOT in train (unseen categories): 0\n",
      "Present in TRAIN but NOT in test: 0\n",
      "\n",
      "========== KS-TEST FOR NUMERICAL FEATURES ==========\n",
      "\n",
      "\n",
      "=== KS TEST: build_year ===\n",
      "KS statistic: 0.0207\n",
      "P-value     : 0.826610\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: facades ===\n",
      "KS statistic: 0.0174\n",
      "P-value     : 0.751306\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: living_area ===\n",
      "KS statistic: 0.0601\n",
      "P-value     : 0.000001\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: number_rooms ===\n",
      "KS statistic: 0.0515\n",
      "P-value     : 0.000037\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: house_age ===\n",
      "KS statistic: 0.0178\n",
      "P-value     : 0.953652\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: is_new_build ===\n",
      "KS statistic: 0.0049\n",
      "P-value     : 1.000000\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: is_recent ===\n",
      "KS statistic: 0.0032\n",
      "P-value     : 1.000000\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: is_old ===\n",
      "KS statistic: 0.0087\n",
      "P-value     : 0.995786\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: build_decade ===\n",
      "KS statistic: 0.0190\n",
      "P-value     : 0.895965\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: garden_flag ===\n",
      "KS statistic: 0.0308\n",
      "P-value     : 0.030269\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: terrace_flag ===\n",
      "KS statistic: 0.0105\n",
      "P-value     : 0.976868\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: swimming_pool_flag ===\n",
      "KS statistic: 0.0097\n",
      "P-value     : 0.985523\n",
      " -> No significant drift\n",
      "\n",
      "=== KS TEST: postal_prefix ===\n",
      "KS statistic: 0.0372\n",
      "P-value     : 0.004534\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: postal_code_num ===\n",
      "KS statistic: 0.0385\n",
      "P-value     : 0.002953\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "=== KS TEST: price ===\n",
      "KS statistic: 0.0791\n",
      "P-value     : 0.000000\n",
      " -> SIGNIFICANT DRIFT DETECTED\n",
      "\n",
      "========== TARGET DRIFT (PRICE DISTRIBUTION) ==========\n",
      "\n",
      "Train price stats:\n",
      "count      9169.000000\n",
      "mean     333646.379213\n",
      "std      125889.858860\n",
      "min       25000.000000\n",
      "25%      246010.000000\n",
      "50%      319000.000000\n",
      "75%      404000.000000\n",
      "max      725000.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Test price stats:\n",
      "count    2.875000e+03\n",
      "mean     3.883394e+05\n",
      "std      2.525057e+05\n",
      "min      2.000000e+04\n",
      "25%      2.499500e+05\n",
      "50%      3.290000e+05\n",
      "75%      4.450000e+05\n",
      "max      2.915000e+06\n",
      "Name: price, dtype: float64\n",
      "\n",
      "========== LOCALITY-LEVEL PRICE DRIFT ==========\n",
      "\n",
      "\n",
      "Train locality price mean distribution:\n",
      "count        51.000000\n",
      "mean     342485.271854\n",
      "std       66647.838628\n",
      "min      230405.870968\n",
      "25%      290109.259091\n",
      "50%      336073.256410\n",
      "75%      377670.468750\n",
      "max      561446.428571\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Test locality price mean distribution:\n",
      "count        51.000000\n",
      "mean     390477.465638\n",
      "std      132206.310891\n",
      "min      220100.647059\n",
      "25%      311629.033333\n",
      "50%      361726.666667\n",
      "75%      419039.177489\n",
      "max      757777.777778\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Locality-level KS test (common localities):\n",
      "KS statistic: 0.2157\n",
      "P-value     : 0.187282\n",
      "\n",
      "==============================\n",
      " DRIFT ANALYSIS COMPLETE\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_clean, X_test, y_train_clean, y_test, preprocessor = run_preprocessing_pipeline(\n",
    "    path=\"data/processed/cleaned_v2.csv\"\n",
    ")\n",
    "\n",
    "drift_check(X_train_clean, X_test, y_train_clean, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd43a3",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "170c0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Train/Test Split (80/20)\n",
    "# -------------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Outlier removal (train only)\n",
    "# -------------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    # IQR filter on price and living_area\n",
    "    def iqr_filter(df, col):\n",
    "        if col not in df.columns:\n",
    "            return df\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    for col in [\"price\", \"living_area\"]:\n",
    "        df_train = iqr_filter(df_train, col)\n",
    "\n",
    "    # Rooms sanity filter\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Train after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Preprocessor\n",
    "# -------------------------------------------------------------\n",
    "def build_preprocessor(X):\n",
    "    numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\", \"Int64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Postal code must be categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"Numeric:\", numeric_cols)\n",
    "    print(\"Categorical:\", categorical_cols)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Evaluate helper\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_rf(model, X, y, split_name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": split_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Train RF\n",
    "# -------------------------------------------------------------\n",
    "def train_random_forest(X_train, y_train, preprocessor):\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\nRandom Forest model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Full RF workflow (Train/Test only)\n",
    "# -------------------------------------------------------------\n",
    "def run_random_forest_no_val(df):\n",
    "\n",
    "    # Split DF\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    # Outliers from train only\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    # Train model\n",
    "    model = train_random_forest(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    results = []\n",
    "    results.append(evaluate_rf(model, X_train_clean, y_train_clean, \"Train\"))\n",
    "    results.append(evaluate_rf(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/random_forest_no_val.pkl\")\n",
    "    print(\"\\nModel saved to models/random_forest_no_val.pkl\")\n",
    "\n",
    "    return model, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e3a7717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 15)\n",
      "Test: (2875, 15)\n",
      "Train after outlier removal: (9169, 15)\n",
      "Numeric: ['build_year', 'facades', 'living_area', 'number_rooms', 'postal_code_num', 'postal_prefix']\n",
      "Categorical: ['garden', 'locality_name', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n",
      "\n",
      "Random Forest model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  16,987.36\n",
      "RMSE: 24,782.33\n",
      "R²:   0.9612\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  90,049.99\n",
      "RMSE: 206,236.78\n",
      "R²:   0.3327\n",
      "\n",
      "Model saved to models/random_forest_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6f10e986-1d58-43b8-b065-d134916af5dd",
       "rows": [
        [
         "0",
         "Train",
         "16987.3554600118",
         "24782.328776833227",
         "0.9612430044231364"
        ],
        [
         "1",
         "Test",
         "90049.99357521866",
         "206236.7838106971",
         "0.3326694150972783"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>16987.355460</td>\n",
       "      <td>24782.328777</td>\n",
       "      <td>0.961243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>90049.993575</td>\n",
       "      <td>206236.783811</td>\n",
       "      <td>0.332669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  16987.355460   24782.328777  0.961243\n",
       "1   Test  90049.993575  206236.783811  0.332669"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run\n",
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "rf_model, rf_results = run_random_forest_no_val(df)\n",
    "rf_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ef054",
   "metadata": {},
   "source": [
    "### Function to train a Random Forest with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5269645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Train/Test Split (80/20)\n",
    "# -------------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Outlier removal (train only)\n",
    "# -------------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    # IQR filter on price and living_area\n",
    "    def iqr_filter(df, col):\n",
    "        if col not in df.columns:\n",
    "            return df\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    for col in [\"price\", \"living_area\"]:\n",
    "        df_train = iqr_filter(df_train, col)\n",
    "\n",
    "    # Rooms sanity filter\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y_train_clean = df_train[\"price\"]\n",
    "    X_train_clean = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Train after outlier removal:\", X_train_clean.shape)\n",
    "    return X_train_clean, y_train_clean\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Preprocessor\n",
    "# -------------------------------------------------------------\n",
    "def build_preprocessor(X):\n",
    "    numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\", \"Int64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Postal code must be categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"Numeric:\", numeric_cols)\n",
    "    print(\"Categorical:\", categorical_cols)\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Evaluate helper\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_rf(model, X, y, split_name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": split_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Train RF\n",
    "# -------------------------------------------------------------\n",
    "def train_random_forest(X_train, y_train, preprocessor):\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\nRandom Forest model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Full RF workflow (Train/Test only)\n",
    "# -------------------------------------------------------------\n",
    "def run_random_forest_no_val(df):\n",
    "\n",
    "    # Split DF\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    # Outliers from train only\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    # Train model\n",
    "    model = train_random_forest(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    results = []\n",
    "    results.append(evaluate_rf(model, X_train_clean, y_train_clean, \"Train\"))\n",
    "    results.append(evaluate_rf(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/random_forest_no_val.pkl\")\n",
    "    print(\"\\nModel saved to models/random_forest_no_val.pkl\")\n",
    "\n",
    "    return model, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ee159",
   "metadata": {},
   "source": [
    "### RUN random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "775d0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 15)\n",
      "Test: (2875, 15)\n",
      "Train after outlier removal: (9169, 15)\n",
      "Numeric: ['build_year', 'facades', 'living_area', 'number_rooms', 'postal_code_num', 'postal_prefix']\n",
      "Categorical: ['garden', 'locality_name', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region']\n",
      "\n",
      "Random Forest model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  16,987.36\n",
      "RMSE: 24,782.33\n",
      "R²:   0.9612\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  90,049.99\n",
      "RMSE: 206,236.78\n",
      "R²:   0.3327\n",
      "\n",
      "Model saved to models/random_forest_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "bfc89bd4-ab4e-46e7-afb9-5e451dc5877e",
       "rows": [
        [
         "0",
         "Train",
         "16987.3554600118",
         "24782.328776833227",
         "0.9612430044231364"
        ],
        [
         "1",
         "Test",
         "90049.99357521866",
         "206236.7838106971",
         "0.3326694150972783"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>16987.355460</td>\n",
       "      <td>24782.328777</td>\n",
       "      <td>0.961243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>90049.993575</td>\n",
       "      <td>206236.783811</td>\n",
       "      <td>0.332669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  16987.355460   24782.328777  0.961243\n",
       "1   Test  90049.993575  206236.783811  0.332669"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "rf_model, rf_results = run_random_forest_no_val(df)\n",
    "rf_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570ec8e",
   "metadata": {},
   "source": [
    "## Tuned Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f16c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 1) Quick train/test split (80/20)\n",
    "#----------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test :\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 2) Outlier removal (train only)\n",
    "#----------------------------------------------------------\n",
    "def remove_outliers_from_train(X_train, y_train):\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"price\"] = y_train\n",
    "\n",
    "    if \"living_area\" in df_train.columns:\n",
    "        Q1, Q3 = df_train[\"living_area\"].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_train = df_train[(df_train[\"living_area\"] >= lower) & (df_train[\"living_area\"] <= upper)]\n",
    "\n",
    "    df_train = df_train[df_train[\"price\"] >= 10000]\n",
    "\n",
    "    if \"number_rooms\" in df_train.columns:\n",
    "        df_train = df_train[df_train[\"number_rooms\"].fillna(0) <= 12]\n",
    "\n",
    "    y = df_train[\"price\"]\n",
    "    X = df_train.drop(columns=[\"price\"])\n",
    "\n",
    "    print(\"Train after outlier removal:\", X.shape)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 3) Safe preprocessor\n",
    "#----------------------------------------------------------\n",
    "def build_preprocessor(X_train):\n",
    "\n",
    "    numeric_cols = X_train.select_dtypes(include=[\"float64\",\"int64\",\"Int64\"]).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=[\"object\",\"string\"]).columns.tolist()\n",
    "\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    # Limit one-hot explosion\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", min_frequency=50)\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", encoder)\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 4) Safe evaluation\n",
    "#----------------------------------------------------------\n",
    "def evaluate_split(model, X, y, split_name):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = mean_squared_error(y, preds) ** 0.5\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {split_name} ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R2:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": split_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 5) Random Forest tuning (safe)\n",
    "#----------------------------------------------------------\n",
    "def train_random_forest_tuned(X_train, y_train, preprocessor):\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # SAFE small grid (won’t crash)\n",
    "    param_grid = {\n",
    "        \"model__n_estimators\": [200, 300],\n",
    "        \"model__max_depth\": [10, 20, 30],\n",
    "        \"model__max_features\": [0.3, 0.5, \"sqrt\"],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,          # small search\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=3,\n",
    "        n_jobs=1,           # IMPORTANT: prevents kernel crash\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest params:\", search.best_params_)\n",
    "    return search.best_estimator_\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 6) Full workflow (No validation)\n",
    "#----------------------------------------------------------\n",
    "def run_random_forest_tuned_no_val(df):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    X_train_clean, y_train_clean = remove_outliers_from_train(X_train, y_train)\n",
    "\n",
    "    preprocessor = build_preprocessor(X_train_clean)\n",
    "\n",
    "    model = train_random_forest_tuned(X_train_clean, y_train_clean, preprocessor)\n",
    "\n",
    "    train_res = evaluate_split(model, X_train_clean, y_train_clean, \"Train\")\n",
    "    test_res = evaluate_split(model, X_test, y_test, \"Test\")\n",
    "\n",
    "    results = pd.DataFrame([train_res, test_res])\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/random_forest_tuned_no_val.pkl\")\n",
    "\n",
    "    print(\"\\nModel saved to models/random_forest_tuned_no_val.pkl\")\n",
    "\n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cea288",
   "metadata": {},
   "source": [
    "## Run random forest tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e342408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11500, 14)\n",
      "Test : (2875, 14)\n",
      "Train after outlier removal: (9672, 14)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best params: {'model__n_estimators': 200, 'model__min_samples_split': 5, 'model__min_samples_leaf': 1, 'model__max_features': 0.3, 'model__max_depth': 30}\n",
      "\n",
      "--- Train ---\n",
      "MAE:  32,774.53\n",
      "RMSE: 57,269.74\n",
      "R2:   0.9029\n",
      "\n",
      "--- Test ---\n",
      "MAE:  85,311.63\n",
      "RMSE: 185,057.98\n",
      "R2:   0.4609\n",
      "\n",
      "Model saved to models/random_forest_tuned_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b8124ccf-5ac7-41dc-be91-44a27e0295c1",
       "rows": [
        [
         "0",
         "Train",
         "32774.5318036082",
         "57269.741780627046",
         "0.9029495553121534"
        ],
        [
         "1",
         "Test",
         "85311.62963841013",
         "185057.9840813905",
         "0.4609377268947009"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>32774.531804</td>\n",
       "      <td>57269.741781</td>\n",
       "      <td>0.902950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>85311.629638</td>\n",
       "      <td>185057.984081</td>\n",
       "      <td>0.460938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  32774.531804   57269.741781  0.902950\n",
       "1   Test  85311.629638  185057.984081  0.460938"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/dtype_cleaned.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "rf_tuned_model, rf_tuned_results = run_random_forest_tuned_no_val(df)\n",
    "rf_tuned_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9f9b6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3377ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. BUILD PREPROCESSOR\n",
    "# ============================================================\n",
    "def build_preprocessor(df):\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\", \"Int64\"]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "    # Postal code must remain categorical\n",
    "    if \"postal_code\" in numeric_cols:\n",
    "        numeric_cols.remove(\"postal_code\")\n",
    "        categorical_cols.append(\"postal_code\")\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. TRAIN XGBOOST (NO VALIDATION SET)\n",
    "# ============================================================\n",
    "def train_xgboost_no_val(X_train, y_train, preprocessor):\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"XGBoost model trained successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. EVALUATE MODEL\n",
    "# ============================================================\n",
    "def evaluate(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. FULL WORKFLOW (80/20 TRAIN-TEST)\n",
    "# ============================================================\n",
    "def run_xgboost_no_val(df):\n",
    "\n",
    "    # --- enforce correct dtype ---\n",
    "    df[\"postal_code\"] = df[\"postal_code\"].astype(\"string\")\n",
    "\n",
    "    # --- split 80/20 ---\n",
    "    X = df.drop(columns=[\"price\"])\n",
    "    y = df[\"price\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "\n",
    "    # --- build preprocessor ---\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "\n",
    "    # --- train model ---\n",
    "    model = train_xgboost_no_val(X_train, y_train, preprocessor)\n",
    "\n",
    "    # --- evaluate ---\n",
    "    results = []\n",
    "    results.append(evaluate(model, X_train, y_train, \"Train\"))\n",
    "    results.append(evaluate(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # --- save model ---\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(model, \"models/xgboost_no_val.pkl\")\n",
    "\n",
    "    print(\"\\nXGBoost (No Validation) saved to models/xgboost_no_val.pkl\")\n",
    "\n",
    "    return model, results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f230eff",
   "metadata": {},
   "source": [
    "### Run XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b41a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 15)\n",
      "Test: (2875, 15)\n",
      "XGBoost model trained successfully.\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  59,607.46\n",
      "RMSE: 92,920.92\n",
      "R²:   0.8788\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  74,591.29\n",
      "RMSE: 144,435.84\n",
      "R²:   0.6727\n",
      "\n",
      "XGBoost (No Validation) saved to models/xgboost_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "45778184-a2fc-4483-bdd8-c6eb348d0a89",
       "rows": [
        [
         "0",
         "Train",
         "59607.45556797738",
         "92920.92381928662",
         "0.8788061614953624"
        ],
        [
         "1",
         "Test",
         "74591.29091576087",
         "144435.8425815073",
         "0.6726904074195689"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>59607.455568</td>\n",
       "      <td>92920.923819</td>\n",
       "      <td>0.878806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>74591.290916</td>\n",
       "      <td>144435.842582</td>\n",
       "      <td>0.672690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  59607.455568   92920.923819  0.878806\n",
       "1   Test  74591.290916  144435.842582  0.672690"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "xgb_model, xgb_results = run_xgboost_no_val(df)\n",
    "xgb_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070a7d6",
   "metadata": {},
   "source": [
    "## Tuned XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1270b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Split into 80% train / 20% test\n",
    "# ---------------------------------------------------------\n",
    "def split_train_test(df, target=\"price\"):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape)\n",
    "    print(\"Test:\", X_test.shape)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Evaluate helper\n",
    "# ---------------------------------------------------------\n",
    "def evaluate_split(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    r2 = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return {\"Split\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Train XGBoost with Hyperparameter Tuning (NO VAL)\n",
    "# ---------------------------------------------------------\n",
    "def train_xgboost_tuned_no_val(X_train, y_train, preprocessor):\n",
    "\n",
    "    # Define default model\n",
    "    base_xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        booster=\"gbtree\",\n",
    "        eval_metric=\"rmse\",\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", base_xgb)\n",
    "    ])\n",
    "\n",
    "    # Parameter grid (lightweight for Windows)\n",
    "    param_dist = {\n",
    "        \"model__n_estimators\": [300, 400, 500],\n",
    "        \"model__learning_rate\": [0.02, 0.05, 0.1],\n",
    "        \"model__max_depth\": [3, 4, 5, 6],\n",
    "        \"model__subsample\": [0.6, 0.8, 1.0],\n",
    "        \"model__colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    print(\"\\nStarting RandomizedSearchCV for XGBoost...\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=3,\n",
    "        n_jobs=1,             # IMPORTANT: fixes BrokenProcessPool\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    return search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Full workflow (train + test)\n",
    "# ---------------------------------------------------------\n",
    "def run_xgboost_tuned_no_val(df, preprocessor):\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "    # Train tuned model\n",
    "    model = train_xgboost_tuned_no_val(X_train, y_train, preprocessor)\n",
    "\n",
    "    # Evaluate\n",
    "    results = []\n",
    "    results.append(evaluate_split(model, X_train, y_train, \"Train\"))\n",
    "    results.append(evaluate_split(model, X_test, y_test, \"Test\"))\n",
    "\n",
    "    # Save\n",
    "    joblib.dump(model, \"models/xgboost_tuned_no_val.pkl\")\n",
    "    print(\"\\nXGBoost (Tuned, No Validation) saved to models/xgboost_tuned_no_val.pkl\")\n",
    "\n",
    "    return model, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbbe27b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11499, 15)\n",
      "Test: (2875, 15)\n",
      "\n",
      "Starting RandomizedSearchCV for XGBoost...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best parameters found:\n",
      "{'model__subsample': 0.8, 'model__n_estimators': 500, 'model__max_depth': 4, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}\n",
      "\n",
      "--- Train Evaluation ---\n",
      "MAE:  65,148.98\n",
      "RMSE: 103,988.05\n",
      "R²:   0.8482\n",
      "\n",
      "--- Test Evaluation ---\n",
      "MAE:  77,759.73\n",
      "RMSE: 148,361.96\n",
      "R²:   0.6547\n",
      "\n",
      "XGBoost (Tuned, No Validation) saved to models/xgboost_tuned_no_val.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "48a62dd7-175f-46c8-9bdb-5d995068402a",
       "rows": [
        [
         "0",
         "Train",
         "65148.97530483289",
         "103988.04565034622",
         "0.8482179775506965"
        ],
        [
         "1",
         "Test",
         "77759.73171127717",
         "148361.9633975367",
         "0.6546544063322017"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>65148.975305</td>\n",
       "      <td>103988.045650</td>\n",
       "      <td>0.848218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>77759.731711</td>\n",
       "      <td>148361.963398</td>\n",
       "      <td>0.654654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split           MAE           RMSE        R2\n",
       "0  Train  65148.975305  103988.045650  0.848218\n",
       "1   Test  77759.731711  148361.963398  0.654654"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/cleaned_v2.csv\", dtype={\"postal_code\": \"string\"})\n",
    "\n",
    "# Build preprocessor correctly\n",
    "preprocessor = build_preprocessor(df.drop(columns=[\"price\"]))\n",
    "\n",
    "# Run tuned XGBoost\n",
    "xgb_model, xgb_results = run_xgboost_tuned_no_val(df, preprocessor)\n",
    "\n",
    "xgb_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9f0c4",
   "metadata": {},
   "source": [
    "## XGboot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2261a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train-only outlier removal\n",
    "# ------------------------------------------------------------\n",
    "def remove_train_outliers(X_train, y_train, columns=None, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Removes outliers from TRAIN ONLY (IQR filtering).\n",
    "    Avoids test leakage.\n",
    "    \"\"\"\n",
    "    df = X_train.copy()\n",
    "    df[\"price\"] = y_train\n",
    "\n",
    "    if columns is None:\n",
    "        columns = [\"price\", \"living_area\", \"number_rooms\"]\n",
    "\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        series = df[col].dropna()\n",
    "        if len(series) < 100:\n",
    "            continue\n",
    "\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower = Q1 - multiplier * IQR\n",
    "        upper = Q3 + multiplier * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "    y_clean = df[\"price\"]\n",
    "    X_clean = df.drop(columns=[\"price\"])\n",
    "    return X_clean, y_clean\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Group-based split\n",
    "# ------------------------------------------------------------\n",
    "def group_split(df, group_col=\"locality_name\", test_size=0.20):\n",
    "    splitter = GroupShuffleSplit(\n",
    "        test_size=test_size,\n",
    "        n_splits=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    groups = df[group_col]\n",
    "    train_idx, test_idx = next(splitter.split(df, groups=groups))\n",
    "\n",
    "    train = df.iloc[train_idx].copy()\n",
    "    test = df.iloc[test_idx].copy()\n",
    "\n",
    "    print(\"Train:\", train.shape)\n",
    "    print(\"Test :\", test.shape)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FINAL XGBoost Training Function\n",
    "# ------------------------------------------------------------\n",
    "def train_xgboost(df, target=\"price\", save_path=\"models/xgboost_geo_tuned.pkl\"):\n",
    "\n",
    "    # 1. Split (geospatial)\n",
    "    train_df, test_df = group_split(df, \"locality_name\")\n",
    "\n",
    "    # 2. Log target\n",
    "    y_train = np.log1p(train_df[target])\n",
    "    y_test = np.log1p(test_df[target])\n",
    "\n",
    "    X_train = train_df.drop(columns=[target])\n",
    "    X_test = test_df.drop(columns=[target])\n",
    "\n",
    "    # 3. TRAIN-ONLY outlier removal\n",
    "    X_train, y_train = remove_train_outliers(\n",
    "        X_train, y_train,\n",
    "        columns=[\"price\", \"living_area\", \"number_rooms\"]\n",
    "    )\n",
    "    print(\"Train after outlier removal:\", X_train.shape)\n",
    "\n",
    "    # 4. Identify column types\n",
    "    cat_cols = X_train.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "    num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    print(\"\\nCategorical:\", cat_cols)\n",
    "    print(\"Numeric:\", num_cols)\n",
    "\n",
    "    # 5. Preprocessing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ])\n",
    "\n",
    "    # 6. XGBoost model\n",
    "    model = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    param_dist = {\n",
    "        \"model__max_depth\": [4, 6, 8],\n",
    "        \"model__learning_rate\": [0.03, 0.05, 0.1],\n",
    "        \"model__n_estimators\": [300, 600, 900],\n",
    "        \"model__subsample\": [0.7, 0.8, 1.0],\n",
    "        \"model__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"model__min_child_weight\": [1, 5, 10],\n",
    "        \"model__gamma\": [0, 1, 5],\n",
    "        \"model__reg_lambda\": [1, 3, 5]\n",
    "    }\n",
    "\n",
    "    print(\"\\nTuning XGBoost hyperparameters...\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        cv=3,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(\"\\nBest hyperparameters:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # 7. Evaluate\n",
    "    preds_train = np.expm1(best_model.predict(X_train))\n",
    "    preds_test = np.expm1(best_model.predict(X_test))\n",
    "\n",
    "    mae_train = mean_absolute_error(train_df[target], preds_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(train_df[target], preds_train))\n",
    "    r2_train = r2_score(train_df[target], preds_train)\n",
    "\n",
    "    mae_test = mean_absolute_error(test_df[target], preds_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(test_df[target], preds_test))\n",
    "    r2_test = r2_score(test_df[target], preds_test)\n",
    "\n",
    "    print(\"\\n===== FINAL XGBOOST RESULTS =====\")\n",
    "    print(\"\\n--- Train ---\")\n",
    "    print(f\"MAE:  {mae_train:,.2f}\")\n",
    "    print(f\"RMSE: {rmse_train:,.2f}\")\n",
    "    print(f\"R²:   {r2_train:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Test ---\")\n",
    "    print(f\"MAE:  {mae_test:,.2f}\")\n",
    "    print(f\"RMSE: {rmse_test:,.2f}\")\n",
    "    print(f\"R²:   {r2_test:.4f}\")\n",
    "\n",
    "    # 8. Save\n",
    "    joblib.dump(best_model, save_path)\n",
    "    print(f\"\\nSaved model to: {save_path}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "60492968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered dataset saved to: data/processed/feature_engineered.csv\n",
      "Final shape: (14374, 23)\n",
      "\n",
      "Columns: ['build_year', 'facades', 'garden', 'living_area', 'locality_name', 'number_rooms', 'postal_code', 'price', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'region', 'garden_flag', 'terrace_flag', 'swimming_pool_flag', 'postal_prefix']\n",
      "Train: (12371, 23)\n",
      "Test : (2003, 23)\n",
      "Train after outlier removal: (9491, 22)\n",
      "\n",
      "Categorical: ['garden', 'locality_name', 'postal_code', 'property_type', 'state', 'swimming_pool', 'terrace', 'province', 'region', 'postal_prefix']\n",
      "Numeric: ['build_year', 'facades', 'living_area', 'number_rooms', 'house_age', 'is_new_build', 'is_recent', 'is_old', 'build_decade', 'garden_flag', 'terrace_flag', 'swimming_pool_flag']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df = feature_engineering()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mtrain_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mtrain_xgboost\u001b[39m\u001b[34m(df, target, save_path)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumeric:\u001b[39m\u001b[33m\"\u001b[39m, num_cols)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# 5. Preprocessing\u001b[39;00m\n\u001b[32m     98\u001b[39m preprocessor = ColumnTransformer([\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, cat_cols),\n\u001b[32m    100\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m, num_cols)\n\u001b[32m    101\u001b[39m ])\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# 6. XGBoost model\u001b[39;00m\n\u001b[32m    104\u001b[39m model = XGBRegressor(\n\u001b[32m    105\u001b[39m     objective=\u001b[33m\"\u001b[39m\u001b[33mreg:squarederror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m     tree_method=\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m    108\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "df = feature_engineering()\n",
    "model = train_xgboost(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "64c5f3c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'postal_prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'postal_prefix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/feature_engineered.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mtrain_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mtrain_xgboost\u001b[39m\u001b[34m(df, target, save_path)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Ensure postal_code and postal_prefix are categorical\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[32m     55\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mpostal_code\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mpostal_code\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mpostal_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpostal_prefix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Split grouped by postal_prefix\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[32m     61\u001b[39m train_df, test_df = group_split(df, group_col=\u001b[33m\"\u001b[39m\u001b[33mpostal_prefix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\welde\\Desktop\\immo-eliza-ml\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'postal_prefix'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/feature_engineered.csv\")\n",
    "model = train_xgboost(df)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
